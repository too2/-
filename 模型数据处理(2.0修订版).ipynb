{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41194755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bed202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000021035</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22826.539964</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.896552</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000018732</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1492.924291</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4     5         6    \\\n",
       "0  P000021035  0.240000  0.313333  0.200000  0.120000  0.02  0.026667   \n",
       "1  P000018732  0.117647  0.176471  0.176471  0.529412  0.00  0.000000   \n",
       "\n",
       "        7         8         9    ...  103  104  105  106  107           108  \\\n",
       "0  0.006667  0.013333  0.013333  ...    0    0    0    3    0  22826.539964   \n",
       "1  0.000000  0.000000  0.000000  ...    0    1    0    4    0   1492.924291   \n",
       "\n",
       "        109       110       111  112  \n",
       "0  0.465517  1.896552  0.293103    1  \n",
       "1  0.733333  0.200000  0.466667    1  \n",
       "\n",
       "[2 rows x 113 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = pd.read_excel('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\POI修订后新的结果\\\\stayregion_feature_train_all.xlsx',header=None)\n",
    "data_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a71a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 836 entries, 0 to 835\n",
      "Columns: 113 entries, 0 to 112\n",
      "dtypes: float64(59), int64(52), object(2)\n",
      "memory usage: 738.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c647100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report  #将主要分类指标以文本输出\n",
    "from sklearn.metrics import confusion_matrix #计算混淆矩阵，主要来评估分类的准确性\n",
    "from sklearn.metrics import accuracy_score #计算精度得分\n",
    "from sklearn.linear_model import LogisticRegression #线性模型中的逻辑回归\n",
    "from sklearn.tree import DecisionTreeClassifier #树算法中的决策树分类包\n",
    "from sklearn.neighbors import KNeighborsClassifier #导入最近邻算法中的KNN最近邻分类包\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #判别分析算法中的线性判别分析包\n",
    "from sklearn.naive_bayes import GaussianNB #朴素贝叶斯中的高斯朴素贝叶斯包\n",
    "from sklearn.svm import SVC  #支持向量机算法中的支持向量分类包\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4a0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.exceptions import ChangedBehaviorWarning\n",
    "\n",
    "## 设置属性防止中文乱码\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ChangedBehaviorWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734c9ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000021035</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>4584.720000</td>\n",
       "      <td>2175.5</td>\n",
       "      <td>5.596790e+07</td>\n",
       "      <td>7481.169530</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22826.539964</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.896552</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000018732</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3114.529412</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>1.803959e+06</td>\n",
       "      <td>1343.115435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1492.924291</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000012504</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.209184</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.188776</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>3894.469388</td>\n",
       "      <td>2688.5</td>\n",
       "      <td>5.787606e+07</td>\n",
       "      <td>7607.631423</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.066327</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>39269.641898</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P000014334</td>\n",
       "      <td>0.329260</td>\n",
       "      <td>0.335370</td>\n",
       "      <td>0.129667</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2487.724372</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>5.275576e+06</td>\n",
       "      <td>2296.862314</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.023761</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.046164</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.050238</td>\n",
       "      <td>0.053632</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.023082</td>\n",
       "      <td>0.084182</td>\n",
       "      <td>0.060421</td>\n",
       "      <td>0.057705</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>0.051595</td>\n",
       "      <td>0.093007</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.045485</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.150820</td>\n",
       "      <td>0.053552</td>\n",
       "      <td>0.028415</td>\n",
       "      <td>0.122404</td>\n",
       "      <td>0.045902</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.192350</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.039344</td>\n",
       "      <td>0.148634</td>\n",
       "      <td>0.085246</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.998907</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>56222.998172</td>\n",
       "      <td>0.537705</td>\n",
       "      <td>0.510383</td>\n",
       "      <td>0.834973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P000015111</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1611.276119</td>\n",
       "      <td>1411.5</td>\n",
       "      <td>7.426041e+05</td>\n",
       "      <td>861.744823</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6878.587426</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0  P000021035  0.240000  0.313333  0.200000  0.120000  0.020000  0.026667   \n",
       "1  P000018732  0.117647  0.176471  0.176471  0.529412  0.000000  0.000000   \n",
       "2  P000012504  0.193878  0.209184  0.352041  0.188776  0.025510  0.000000   \n",
       "3  P000014334  0.329260  0.335370  0.129667  0.161575  0.031908  0.008147   \n",
       "4  P000015111  0.365672  0.477612  0.134328  0.022388  0.000000  0.000000   \n",
       "\n",
       "        7         8         9         10        11   12        13   \\\n",
       "0  0.006667  0.013333  0.013333  0.026667  0.006667  0.0  0.013333   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2  0.005102  0.005102  0.000000  0.000000  0.000000  0.0  0.020408   \n",
       "3  0.002716  0.001358  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           14      15            16           17        18        19   \\\n",
       "0  4584.720000  2175.5  5.596790e+07  7481.169530  0.026667  0.033333   \n",
       "1  3114.529412  3600.0  1.803959e+06  1343.115435  0.000000  0.000000   \n",
       "2  3894.469388  2688.5  5.787606e+07  7607.631423  0.035714  0.025510   \n",
       "3  2487.724372  1670.0  5.275576e+06  2296.862314  0.031229  0.023761   \n",
       "4  1611.276119  1411.5  7.426041e+05   861.744823  0.029851  0.007463   \n",
       "\n",
       "        20        21        22        23        24        25        26   \\\n",
       "0  0.026667  0.026667  0.026667  0.040000  0.040000  0.046667  0.026667   \n",
       "1  0.176471  0.000000  0.000000  0.058824  0.000000  0.000000  0.000000   \n",
       "2  0.030612  0.056122  0.010204  0.025510  0.025510  0.045918  0.051020   \n",
       "3  0.031229  0.046164  0.035981  0.039375  0.050238  0.053632  0.037339   \n",
       "4  0.014925  0.052239  0.014925  0.037313  0.067164  0.007463  0.074627   \n",
       "\n",
       "        27        28        29        30        31        32        33   \\\n",
       "0  0.046667  0.073333  0.053333  0.066667  0.046667  0.040000  0.073333   \n",
       "1  0.000000  0.000000  0.000000  0.058824  0.058824  0.000000  0.058824   \n",
       "2  0.056122  0.081633  0.066327  0.086735  0.045918  0.025510  0.051020   \n",
       "3  0.027155  0.013578  0.023082  0.084182  0.060421  0.057705  0.031229   \n",
       "4  0.029851  0.029851  0.029851  0.223881  0.097015  0.014925  0.044776   \n",
       "\n",
       "        34        35        36        37        38        39        40   \\\n",
       "0  0.040000  0.053333  0.060000  0.046667  0.033333  0.020000  0.013333   \n",
       "1  0.058824  0.000000  0.235294  0.176471  0.000000  0.058824  0.000000   \n",
       "2  0.030612  0.040816  0.061224  0.015306  0.045918  0.040816  0.025510   \n",
       "3  0.025798  0.051595  0.093007  0.061100  0.045485  0.014257  0.030550   \n",
       "4  0.014925  0.014925  0.074627  0.037313  0.022388  0.014925  0.029851   \n",
       "\n",
       "        41        42        43        44        45        46        47   \\\n",
       "0  0.040000  0.034483  0.034483  0.034483  0.086207  0.120690  0.068966   \n",
       "1  0.058824  0.266667  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.020408  0.060606  0.068182  0.022727  0.242424  0.068182  0.030303   \n",
       "3  0.031908  0.150820  0.053552  0.028415  0.122404  0.045902  0.021858   \n",
       "4  0.014925  0.125000  0.052083  0.000000  0.166667  0.031250  0.020833   \n",
       "\n",
       "        48        49        50        51        52        53        54   \\\n",
       "0  0.189655  0.086207  0.120690  0.068966  0.051724  0.103448  0.000000   \n",
       "1  0.133333  0.066667  0.000000  0.466667  0.066667  0.000000  0.000000   \n",
       "2  0.250000  0.045455  0.022727  0.121212  0.030303  0.037879  0.000000   \n",
       "3  0.192350  0.081967  0.039344  0.148634  0.085246  0.029508  0.001093   \n",
       "4  0.281250  0.062500  0.041667  0.156250  0.052083  0.010417  0.000000   \n",
       "\n",
       "        55            56   57   58   59   60   61   62   63   64   65   66   \\\n",
       "0  1.000000  unclassified    0    0    0    0    0    0    0    0    0    0   \n",
       "1  1.000000     secondary    0    0    0    0    0    0    0    0    0    0   \n",
       "2  1.000000      tertiary    0    0    0    0    0    0    0    0    0    0   \n",
       "3  0.998907      tertiary    0    0    0    0    0    0    0    0    0    0   \n",
       "4  1.000000     secondary    0    0    0    0    0    0    0    0    0    1   \n",
       "\n",
       "   67   68   69   70   71   72   73   74   75   76   77   78   79   80   81   \\\n",
       "0    0    0    0    0    0    1    0    1    0    0    0    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "3    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0   \n",
       "4    0    1    0    0    0    3    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96   \\\n",
       "0    0    0    0    0    0    0    0    2    0    1    0    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0   \n",
       "2    2    0    0    0    0    0    0    2    0    0    0    1    0    0    0   \n",
       "3    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0   \n",
       "4    0    1    0    1    0    0    0   11    0    2    0    2    0    0    0   \n",
       "\n",
       "   97   98   99   100  101  102  103  104  105  106  107           108  \\\n",
       "0    0    0    1    0    0    0    0    0    0    3    0  22826.539964   \n",
       "1    1    4   11    3    0    2    0    1    0    4    0   1492.924291   \n",
       "2    0    1    7    2    0    2    1    0    0   15    0  39269.641898   \n",
       "3    0    0    4    0    0    0    0    0    0   24    0  56222.998172   \n",
       "4    1    5   20    6    0    6    0    0    0   41    0   6878.587426   \n",
       "\n",
       "        109       110       111  112  \n",
       "0  0.465517  1.896552  0.293103    1  \n",
       "1  0.733333  0.200000  0.466667    1  \n",
       "2  0.598485  0.810606  0.136364    1  \n",
       "3  0.537705  0.510383  0.834973    1  \n",
       "4  0.385417  0.531250  0.708333    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据\n",
    "df = data_all\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b55418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#最大最小归一化\n",
    "cols=[14,15,16,17,108]   # 可以改成自己需要的列的名字\n",
    "for item in cols:\n",
    "    max_tmp = np.max(np.array(df[item]))\n",
    "    min_tmp = np.min(np.array(df[item]))\n",
    "    if (max_tmp != min_tmp):\n",
    "        df[item] = df[item].apply(lambda x: (x - min_tmp) / (max_tmp - min_tmp))\n",
    "# 0-1标准化\n",
    "# cols=list(df)   # 可以改成自己需要的列的名字\n",
    "# for item in cols:\n",
    "#     mean_tmp = np.mean(np.array(df[item]))\n",
    "#     std_tmp = np.std(np.array(df[item]))\n",
    "#     if(std_tmp):\n",
    "#         df[item] = df[item].apply(lambda x: (x - mean_tmp) / std_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ade3500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000021035</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.06182</td>\n",
       "      <td>0.248637</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.896552</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1         2    3     4     5         6         7         8    \\\n",
       "0  P000021035  0.24  0.313333  0.2  0.12  0.02  0.026667  0.006667  0.013333   \n",
       "\n",
       "        9         10        11   12        13        14        15       16   \\\n",
       "0  0.013333  0.026667  0.006667  0.0  0.013333  0.088733  0.033989  0.06182   \n",
       "\n",
       "        17        18        19        20        21        22    23    24   \\\n",
       "0  0.248637  0.026667  0.033333  0.026667  0.026667  0.026667  0.04  0.04   \n",
       "\n",
       "        25        26        27        28        29        30        31    32   \\\n",
       "0  0.046667  0.026667  0.046667  0.073333  0.053333  0.066667  0.046667  0.04   \n",
       "\n",
       "        33    34        35    36        37        38    39        40    41   \\\n",
       "0  0.073333  0.04  0.053333  0.06  0.046667  0.033333  0.02  0.013333  0.04   \n",
       "\n",
       "        42        43        44        45       46        47        48   \\\n",
       "0  0.034483  0.034483  0.034483  0.086207  0.12069  0.068966  0.189655   \n",
       "\n",
       "        49       50        51        52        53   54   55            56   \\\n",
       "0  0.086207  0.12069  0.068966  0.051724  0.103448  0.0  1.0  unclassified   \n",
       "\n",
       "   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   72   73   74   75   76   77   78   79   80   81   82   83   84   85   86   \\\n",
       "0    1    0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   87   88   89   90   91   92   93   94   95   96   97   98   99   100  101  \\\n",
       "0    0    0    2    0    1    0    0    0    0    0    0    0    1    0    0   \n",
       "\n",
       "   102  103  104  105  106  107       108       109       110       111  112  \n",
       "0    0    0    0    0    3    0  0.004602  0.465517  1.896552  0.293103    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096ee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df[56]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd20c1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motorway</th>\n",
       "      <th>primary</th>\n",
       "      <th>residential</th>\n",
       "      <th>secondary</th>\n",
       "      <th>service</th>\n",
       "      <th>tertiary</th>\n",
       "      <th>trunk</th>\n",
       "      <th>unclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     motorway  primary  residential  secondary  service  tertiary  trunk  \\\n",
       "0           0        0            0          0        0         0      0   \n",
       "1           0        0            0          1        0         0      0   \n",
       "2           0        0            0          0        0         1      0   \n",
       "3           0        0            0          0        0         1      0   \n",
       "4           0        0            0          1        0         0      0   \n",
       "..        ...      ...          ...        ...      ...       ...    ...   \n",
       "831         0        0            0          0        0         0      1   \n",
       "832         0        0            0          0        0         0      1   \n",
       "833         0        1            0          0        0         0      0   \n",
       "834         0        0            0          0        0         1      0   \n",
       "835         0        0            0          0        0         1      0   \n",
       "\n",
       "     unclassified  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "831             0  \n",
       "832             0  \n",
       "833             0  \n",
       "834             0  \n",
       "835             0  \n",
       "\n",
       "[836 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314ba8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>motorway</th>\n",
       "      <th>primary</th>\n",
       "      <th>residential</th>\n",
       "      <th>secondary</th>\n",
       "      <th>service</th>\n",
       "      <th>tertiary</th>\n",
       "      <th>trunk</th>\n",
       "      <th>unclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000021035</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.061820</td>\n",
       "      <td>0.248637</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.896552</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000018732</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>0.062990</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4     5         6  \\\n",
       "0  P000021035  0.240000  0.313333  0.200000  0.120000  0.02  0.026667   \n",
       "1  P000018732  0.117647  0.176471  0.176471  0.529412  0.00  0.000000   \n",
       "\n",
       "          7         8         9        10        11   12        13        14  \\\n",
       "0  0.006667  0.013333  0.013333  0.026667  0.006667  0.0  0.013333  0.088733   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.056749   \n",
       "\n",
       "         15        16        17        18        19        20        21  \\\n",
       "0  0.033989  0.061820  0.248637  0.026667  0.033333  0.026667  0.026667   \n",
       "1  0.062990  0.001993  0.044638  0.000000  0.000000  0.176471  0.000000   \n",
       "\n",
       "         22        23    24        25        26        27        28        29  \\\n",
       "0  0.026667  0.040000  0.04  0.046667  0.026667  0.046667  0.073333  0.053333   \n",
       "1  0.000000  0.058824  0.00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         30        31    32        33        34        35        36        37  \\\n",
       "0  0.066667  0.046667  0.04  0.073333  0.040000  0.053333  0.060000  0.046667   \n",
       "1  0.058824  0.058824  0.00  0.058824  0.058824  0.000000  0.235294  0.176471   \n",
       "\n",
       "         38        39        40        41        42        43        44  \\\n",
       "0  0.033333  0.020000  0.013333  0.040000  0.034483  0.034483  0.034483   \n",
       "1  0.000000  0.058824  0.000000  0.058824  0.266667  0.000000  0.000000   \n",
       "\n",
       "         45       46        47        48        49       50        51  \\\n",
       "0  0.086207  0.12069  0.068966  0.189655  0.086207  0.12069  0.068966   \n",
       "1  0.000000  0.00000  0.000000  0.133333  0.066667  0.00000  0.466667   \n",
       "\n",
       "         52        53   54   55            56  57  58  59  60  61  62  63  64  \\\n",
       "0  0.051724  0.103448  0.0  1.0  unclassified   0   0   0   0   0   0   0   0   \n",
       "1  0.066667  0.000000  0.0  1.0     secondary   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  \\\n",
       "0   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  100  101  \\\n",
       "0   0   0   0   0   0   2   0   1   0   0   0   0   0   0   0   1    0    0   \n",
       "1   0   0   0   0   0   0   0   2   0   0   0   0   0   1   4  11    3    0   \n",
       "\n",
       "   102  103  104  105  106  107       108       109       110       111  112  \\\n",
       "0    0    0    0    0    3    0  0.004602  0.465517  1.896552  0.293103    1   \n",
       "1    2    0    1    0    4    0  0.000301  0.733333  0.200000  0.466667    1   \n",
       "\n",
       "   motorway  primary  residential  secondary  service  tertiary  trunk  \\\n",
       "0         0        0            0          0        0         0      0   \n",
       "1         0        0            0          1        0         0      0   \n",
       "\n",
       "   unclassified  \n",
       "0             1  \n",
       "1             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053f5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([56], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb2dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\POI修订后新的结果\\\\train_and_all处理后的训练数据.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e783fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.drop([0], axis = 1)\n",
    "df_train = df_train.drop([112], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af748584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     112\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "..   ...\n",
       "831    4\n",
       "832    4\n",
       "833    4\n",
       "834    4\n",
       "835    4\n",
       "\n",
       "[836 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义标签\n",
    "df_tag = df[112]\n",
    "df_tag = df_tag.to_frame()\n",
    "df_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dd677d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112\n",
       "1      451\n",
       "0      225\n",
       "3       89\n",
       "2       47\n",
       "4       24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4602b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割数据集以8:2划分训练验证集和测试集\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(df_train, df_tag, test_size = 0.4, random_state = 0, stratify= df_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b5939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.732745 (0.058087)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.840549 (0.054690)\n",
      "LDA: 0.818667 (0.071480)\n",
      "CART: 0.770627 (0.040873)\n",
      "NB: 0.491020 (0.040112)\n",
      "SVM: 0.676980 (0.077766)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7014925373134329\n",
      "[[ 52  38   0   0   0]\n",
      " [  1 180   0   0   0]\n",
      " [  2  17   0   0   0]\n",
      " [ 11  24   0   0   1]\n",
      " [  4   2   0   0   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65        90\n",
      "           1       0.69      0.99      0.81       181\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        36\n",
      "           4       0.75      0.33      0.46         9\n",
      "\n",
      "    accuracy                           0.70       335\n",
      "   macro avg       0.44      0.38      0.39       335\n",
      "weighted avg       0.59      0.70      0.63       335\n",
      "\n",
      "238 has been classified as  1 and should be  112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = [] #建立列表\n",
    "models.append(('KNN', KNeighborsClassifier())) #往maodels添加元组（算法名称，算法函数）\n",
    "models.append(('LR', LogisticRegression())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "results = []\n",
    "names = []\n",
    "# seed = 7\n",
    "\n",
    "for name, model in models: #将算法名称与函数分别读取\n",
    "    kfold = model_selection.KFold(n_splits=10) #建立10倍交叉验证\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "# Make predictions on validation dataset\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn = KNeighborsClassifier(n_neighbors=18, weights= 'distance', algorithm='auto',\n",
    "#                            leaf_size=5, p=2, metric='minkowski', metric_params=None, n_jobs=-1)#调参\n",
    "# knn.fit(X_train, Y_train) #knn拟合序列集\n",
    "# predictions = knn.predict(X_validation) #预测验证集\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train.values.ravel())\n",
    "predictions = svc.predict(X_validation)\n",
    "\n",
    "print(accuracy_score(Y_validation, predictions)) #验证集精度得分\n",
    "print(confusion_matrix(Y_validation, predictions)) #混淆矩阵\n",
    "print(classification_report(Y_validation, predictions)) #分类预测报告\n",
    "\n",
    "# 找出分类错误的样本\n",
    "errors = []\n",
    "inputs = X_validation\n",
    "labels = Y_validation\n",
    "predictions = svc.predict(inputs)\n",
    "for inputt, prediction, label in zip(inputs.index.tolist(), predictions, labels):\n",
    "    if prediction != label:\n",
    "        print(inputt, 'has been classified as ', prediction, 'and should be ', label) \n",
    "        errors.append(inputt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e39fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582089552238805\n",
      "[[ 65   7   5   8   5]\n",
      " [ 14 159   4   3   1]\n",
      " [  5   6   6   2   0]\n",
      " [  4   6   4  21   1]\n",
      " [  5   0   0   1   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        90\n",
      "           1       0.89      0.88      0.89       181\n",
      "           2       0.32      0.32      0.32        19\n",
      "           3       0.60      0.58      0.59        36\n",
      "           4       0.30      0.33      0.32         9\n",
      "\n",
      "    accuracy                           0.76       335\n",
      "   macro avg       0.56      0.57      0.56       335\n",
      "weighted avg       0.76      0.76      0.76       335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "cart = DecisionTreeClassifier()\n",
    "cart.fit(X_train, Y_train)\n",
    "predictions = cart.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions)) #验证集精度得分\n",
    "print(confusion_matrix(Y_validation, predictions)) #混淆矩阵\n",
    "print(classification_report(Y_validation, predictions)) #分类预测报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9bb6028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(30.5, 0.5, 'true')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEXCAYAAABf36TeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzhklEQVR4nO3deVxU9frA8Q8Oi6JNpoIbipmaZS5puWSKeRURJAWtpFTMzDTB5ZqKuJW5Z65kPzM1d8VduYhLXimDMrWrYi6pgCIIuJIp28z5/dG90xAaAzPDYabn3eu8XpwzZ873OQ0+fOc53/M9DoqiKAghhLBp5dQOQAghhPkkmQshhB2QZC6EEHZAkrkQQtgBSeZCCGEHJJkLIYQdkGQurGb79u106tSJd955p0Tvf/fdd7l48aKFoyq5iIgIDh48+NDXFi1axM6dO0s3ICGMOMg4c2EtAwYMoHfv3vTs2VPtUCyif//+vPXWW/j4+KgdihCFOKodgChbtm7dyqpVqyhXrhxPPPEEc+bMoWbNmmzevJm1a9dSrlw5qlWrxuTJk3nyyScJCwujUqVKnD9/nuvXr/P0008zZ84cFi1axOnTp0lJSeH27ducO3eOhg0bGnrpYWFhhvUNGzawadMmnJyccHFxYdq0aTRo0IDOnTuzaNEimjZtWuz2K1asWOC8wsLCKF++PBcuXODmzZt07tyZypUr8+9//5vMzEymT59Ou3btSExMZNq0afz2229kZmbSuHFjFi5cyNatW0lISGDu3LloNBq+/vpr7ty5w9WrV+nUqRM3b96kYcOGdOrUib59+7JmzRqeeeYZxo0bh6OjIzNnzlTj4xR/J4oQ/3X27FmlTZs2SmpqqqIoirJq1Spl8uTJSlxcnNKlSxfl5s2biqIoyrZt25Tu3bsrer1eGT9+vPLGG28oOTk5Sm5urtKrVy9l69atiqIoSr9+/ZS9e/cqiqIo48ePV7788ktDW/9bz8/PV5o0aaKkp6criqIoO3bsUDZt2qQoiqK88soryqlTp0rcvrHx48crr732mpKbm6tkZGQojRo1UtasWaMoiqJ89dVXyttvv60oiqLMnj1b2blzp6IoipKbm6v06NFDiYmJeej5BAcHFzofRVGUzZs3K/7+/kpkZKTi7++vPHjwwKzPRQhTSM1cGMTHx/Pyyy9Ts2ZNAAYOHMi0adP49ttv8fX1pUqVKgAEBgaSnp5OSkoKAB06dMDZ2RknJycaNWrE3bt3TW5To9Hg4+ND3759mTZtGlqtlj59+hTYx1Ltv/LKKzg5OeHm5oarqysdOnQAoG7duty5cweAsWPHUqVKFZYvX86HH35IRkYG9+/ff+jxWrVq9dDtr7/+OvXq1WP69OksXryY8uXLm/z/Q4iSkjKLMNBoNDg4OBjWs7OzuXbtGnq9vtC+iqKQn58PUCBZOTg4oDzkMsyft+fl5Rl+njdvHhcuXCAuLo4vvviCXbt2sWjRIsPrlmgfwNnZucC6o2PhX/9//vOf6HQ6unfvTqdOnUhLS3vk8VxdXR+6PTc3l+TkZB577DHOnj1LvXr1HrqfEJYkPXNh0KZNG+Lj48nIyABg06ZNfPLJJ3To0IHo6Ghu3boFwLZt26hcuTKenp4mH/uJJ54gISEBgPT0dI4ePQrArVu38PLyonLlygwcOJBRo0Zx+vTpAu+1RPumOnLkCMOHD8fX1xeAkydPotPpgN//2P3vD8hfmTt3Lg0bNmTFihVMnz6da9euWTxOIf5MeubC4Omnn2bs2LEMHjwYADc3N2bOnEn16tUZOHAgwcHB6PV6qlSpwrJlyyhXzvS+QP/+/fnggw/o1q0bHh4etG3bFoAqVaowbNgwBg4cSPny5dFoNEyfPr3Ae9u3b292+6YaPXo0w4cPx9XVlUqVKvHiiy9y5coVADp37sz8+fMLfKv4s8OHD3PgwAH27NmDVqslODiYMWPGsG7duod+ExDCUmRoohBC2AEpswghhB2QZC6EEHZAkrkQQtgBSeZCCGEHJJkLIYQdsImxUutr9VM7BIsL/fUHtUOwuHy9Tu0QrMJZYxP/TIolV1f0eHlblfXbZbPen3fD9Pc7VatvVluWZH+/pUIIYQ4b7ZRIMhdCCGNK4ekjbIEkcyGEMPaQuYBsgSRzIYQwokjPXAgh7ICNXhyWZC6EEMbkAqgQQtgBKbMIIYQdkAugQghh++QCqBBC2APpmQshhB3QPfpJUmWZJHMhhDAmZRYhhLADUmYRQgg7ID1zIYSwA9IzF0II26fo5QKoTanc2IMXpgfjpK2AotNzdNxKbp1OonfC59xPu2XY7+zSf5G0I07FSEvmjaBevB8yyLCu1VaiVu0aPPd0BzIzb6oYmflmzAqnV4Avt2/fAeCXC5d5O3iEukGZybdHV8aHh6LXK9y5fYfRIyaRlHhV7bDMZpOflfTMbYemgjOdN4bx/ZjlpB46iUe3lrz02fvEvr2A3Nv32Nt1otohmm3zxp1s3rgTAEdHR/61bwML539h84kcoE2blrwdPIKjP5xQOxSLKF/ehc+Xf0Kn9q+SePkKQ4cPZNbcyQS9NkTt0Mxmk5+V1MwLunTpEvv27eP69euUK1cOd3d3OnToQNOmTa3VpMlqejXl1+R0Ug+dBCBl3wnuXcnE7YWGKHo9XXdMxumxClz511HOLNqFoldUjtg8I0cPITPzJqtXbVI7FLM5OzvTrHkTRo0ewpP1Pbn4SyITxk8nJSVV7dBKTKPR4ODggFb7GAAVK7qSnZ2jclTms9nPSiba+sP69euJjIykW7duhuSdmZnJ5MmTefXVVxk0aFARR7Aubf0aZGfcpc2ng3ni2brkZt3np+mbcNCU4/q3Z/hpxmbKOWl4Ze0H5P36gPNf7lM1XnNUqfoEw0MH8UrHALVDsYiaNd35Jjaej6fN5+zPFxgx6l02Ri6jw0v+aodWYr/9dp8PRk8l+sBmbt+6TTmNBj/vvmqHZTab/axstGfuoCiKxbud3bp1Y+fOnVSoUKHA9gcPHhAQEEBMTEyxjmfpBzo3GfEqz43sycE+M7n50yU8urWk9ZxB7Gw9Cn3uH3MZ1/F9kaff8eZg7xkWbR9K74HOoz8YylMNniRk6Hirt6XWA51T0k7Svq0fyckpVjm+tR/o/MyzjVi94TNeDxhEUuJV3h3an7f6v0an9q9arU21Huhs7c8KzH+gc/b3m03et3zbN8xqy5LKWeOgjo6O5OcX/mXJzs7GycnJGk0Wy4P0O9z9JZWbP10Cfi+zOGjK8ez7Paj8TJ0/dnQAfb5tfuX6n4BAXzas3aZ2GBbT5LnG9A3qVWCbg4MDeXm2+UABgM7/eJmj358wXPBc8cV6nnm2IVWqPKFyZOax2c9Kl2/6Ukz37t2jR48epKQU/GO2bt06+vfvb1g/e/YsgYGBdOvWjYkTJz40n/6ZVZL50KFD6dWrF5MmTWLRokUsXryYSZMm8dprrzF06FBrNFksqYdOUqmOG1Wa1gPAvc3ToCg4VnSh2djeOJRzQFPeiaff9iZ51/fqBmuGxytrebK+p21dfCqCXq9nzidT8fT0AGDwu/04k3CO1NTrKkdWcqdO/sxL7V/Eza0qAL49upCcnMKtW7dVjsw8NvtZ6fWmL8Vw8uRJgoKCSEpKKrD94sWLfPHFFwW2jR07lilTprBv3z4URSEyMrLI41vl+6O/vz+tW7cmPj6ejIwM9Ho9L7zwAqGhoVSvXt0aTRZLduZdvhm0gBdnDcTR1QVdbj7fDF7ErdNJvDgjGL9Ds3Fw1HAl6iiXNhxWO9wSq1/fk/TrmSb9VbcVZ3++wLgPPmTz1uVoymm4lnqdQQNHqR2WWb795nsiFq9gV/Q6cnPzuHP7Dv37DlM7LLPZ6melKNb5Nh4ZGcnUqVMZN26cYVtubi5TpkxhxIgR7Nq1C4Br166RnZ1NixYtAAgMDGTx4sW8+eabf3l8q9TMLc3SNfOyoLRq5qVJrZq5tVm7Zq4GtWrmpcHcmvmDwytN3jevZR+ysrIKbddqtWi12oe+p3PnzqxZswYPDw9mzZpFo0aN8PDwICIigrVr1/LTTz8xd+5cNm7cCEBycjJDhgxh376/Hohhf7+lQghhjmKMZlm9ejURERGFtoeEhBAaGvqX7/3uu+9IS0tjwoQJ/PDDH507vV6Pg4PDH+EoSoH1R5FkLoQQxorxrSU4OJiAgMLDfh/VKzcWFRXFL7/8Qs+ePbl//z43btxg1KhRjB07lszMTMN+N27cwN3dvcjjSTIXQghjxbiw+VfllKLMmjXL8PMPP/xAREQECxcuBMDFxYXjx4/TqlUrdu3aRceOHYs8niRzIYQwVgZuGpo3bx6TJk3i3r17NGnShAEDBhT5HrkAqhK5AGo75AKobTH7AujexSbvW6F72Zk0zP5+S4UQwhwya6IQQtiBMlBmKQlJ5kIIYcxGS1CSzIUQwpiUWYQQwg5ImUUIIeyA9MyFEMIOSDIXQgg7UPZvvXkoSeZCCGHMRqeMlmQuhBDG5AKoEELYAamZCyGEHZCaufVMzj2jdggWl574108NsUWV63ZWOwSruJebrXYIFqez00nRLEJ65kIIYQfkdn4hhLB9il7KLEIIYfukzCKEEHZAhiYKIYQdkDKLEELYARsts5RTOwAhhChTdDrTl2K6d+8ePXr0ICUlBYDNmzfTo0cP/P39mTBhArm5uQCcPXuWwMBAunXrxsSJE8k3YYoBSeZCCGFMrzd9KYaTJ08SFBREUlISAImJiaxYsYJNmzaxe/du9Ho9GzZsAGDs2LFMmTKFffv2oSgKkZGRRR5fkrkQQhjTKyYvWVlZpKSkFFqysrIKHTYyMpKpU6fi7u4OgLOzM1OnTqVSpUo4ODjQqFEjUlNTuXbtGtnZ2bRo0QKAwMBAYmJiigxbauZCCGGsGKNZVq9eTURERKHtISEhhIaGFtg2Y8aMAuu1a9emdu3aANy6dYv169cza9YsMjIycHNzM+zn5uZGenp6kbFIMhdCCGPFGM0SHBxMQEBAoe1ardbkY6SnpzN48GB69+5NmzZtOH78OA4ODobXFUUpsP4oksyFEMKIUoxauFarLVbi/rNLly4xePBg+vfvz6BBgwCoUaMGmZmZhn1u3LhhKM38FamZCyGEMSuOZjF279493nnnHUaOHGlI5PB7+cXFxYXjx48DsGvXLjp27Fjk8aRnLoQQxkrppqGtW7dy48YNVq1axapVqwDo3LkzI0eOZN68eUyaNIl79+7RpEkTBgwYUOTxHBSl7E/eW7/a82qHYHHnz21TOwSLs9cpcHU2ehPJX7HnKXDzcq+Z9f7fPgwyed+KH240qy1Lkp65EEIYs9Hb+f/2NfNPIqYxeHj/Qts//2oeH84er0JEv1MUhfCP57Fqw9aHvn7hUiIDQ8bRZ+BwXh80gjPnfjGrvVu37zB0zGRefWsIvfoN5afTPxte27PvEIHB79M7eDhvvfdPEs5eMKstS+jh78319AS1w7CYoUODOXHiIMePH2DLli9xc6uqdkgWtXLFQkaPfk/tMEyj6E1fypC/bTJ/quGTrNuxjO7+XQq9NiQ0mBfatlQhqt9dSrrCOyMmcODwkYe+/iA7myGjJzLozT5s/eozhr4dRNhHc81qc8b8pbRs1oTd679g9pSxjJk0kwfZ2SQmp/DpZ1+y7NPpbFv9Ge8F92XUxOlmtWWup56qx8yZ4SYN17IFzz/flNGjh9CpUwCtWnXl4sVEpk79QO2wLKJx4wbs3xdJYKCf2qGYTMnXmbyUJX/bMkv/d14nct0OUlOuF9jepn0rOnZ+iQ1fbeXxyo+pEtumbVH09u9GzepuD3097ugJ6tSuSceXWgPwysttqV2zBgB5eXnMX7qSY/85jU6v55mGTzFh9FAqVaxoeP/E6Z/y4vPN6OXXFYD8fB2x3x1l4j/fB6Bxo6eoW6cWR74/zrNPN+CjsFG4VasCQJNnGnHj5m3y8vJwcnKy2v+DR6lQoTwrVi4kLGw6q1YtKvX2reGnn07TpIkX+fn5uLi4ULt2DZKSrqodlkUMGzqQlas2cPWqeXXsUiVlFtvyYdgcdm8reIusew03pswYx+ihE9GreIFo4pj38fN+5ZGvJ1+9RrUqTzB51gJeHzSCd0eFo/vvMKkv10ai0WiIXLmE7auX4latKgs+X/WX7d25exe9oqfKE5UN26q7VSM98wa1a1bH679/NBRFYe7iL3jl5TaqJHKAJUtmsnLFehJOn1OlfWvJz8/H39+bS5d+oH37NqxeXfRcHLZg5KhJbNq0U+0wiqcYt/OXJX/bnvmfOTo6suiLWUyfPI/M9Btqh/OX8vLz+Tb+GCuXzKZZk8Yc+jaeYR9M4cC2r4iNO8qv934j/sef/rtvniFJB707itzcPNLSM/jhxEnWRu7k+WbPMmRAXxz4U8lCUdCU++Nv/f0H2Uya8SnX0zP5v/nqlFneHdKPfJ2ONWu2ULeuhyoxWNOePfvZs2c/gwYFERW1jmef7YANDDazP2WsFm4qqyTz1NTUv3y9Vq1a1mjWLE1bPEsdz9pMnDYGADf3qpTTaHAp78KEUdNUjq4g92pVqV+vDs2aNAagc4d2TJ29kKup19Hr9YSNfI8O7V4E4P79B+T8d1rNjcsXAg8vsygo3M36lce1v5eWMm7corp7NQDSrmcwfPyH1Pesw8qIOZR3cSnN0zXo168PrhUqEP99NE5OTlSoUJ7476MJCBjI9bQMVWKyhPr1PalRw524uB8B+OqrzSxZMpMnnnicW7fuqBvc31EZ63GbyirJ/L333iMpKQl3d/dCPQsHBwe+/vprazRrlp+OneLl5t0N6yPHvccTVSrzYdgcFaN6uA5tX+CTJcs5c+4XmjRuyLH/nMYBBzxq1uCl1q3YsG0PbV9ogUajYeqcRbhWqMBHYSMfeTxHRw0d27Vmy669DO7/OucvJnIp6QovPt+M3367z9uh43m1exfeH/RWKZ5lYV4dexl+rlvXgx+P7aNdW1/1ArKQmjWrs3r1Etq08eHmzdsEBQVw5sx5SeQqkQc6G9m4cSNvvvkmU6dOpVWrVtZo4m8n4ewFps5exLbVn1GtahUWz57C9E8/48GDbJydnVg4cxIuLs4MfTuIeRFf0mdgCHq9nqcb1mds6OACx5oxaUyh40/6YDhTZy+kV7+hODg4MGvyBzxWqSLL12wm9XoGX8fG8XVsnGH/FYtnUfnxks9JIf7w3XdHmTNnCfv3R5Kfn09aWjqvv/6u2mH9fZWxUSqmstodoKdOnWLLli18/PHHZh9L7gC1DXIHqO2QO0Af7df3uxe90389tnSvWW1ZktUugDZr1oxmzZpZ6/BCCGEdUmYRQgjbZ6sjiCSZCyGEMemZCyGEHZBkLoQQtk/Jt80L3pLMhRDCmG3mcknmQghhTG4aEkIIe2CjyfxvO2uiEEI8lL4YSzHdu3ePHj16kJKSAkBcXBz+/v54e3uzYMECw35nz54lMDCQbt26MXHiRPLz84s8tiRzIYQwouQrJi/FcfLkSYKCgkhKSgIgOzub8PBwli5dSnR0NAkJCcTGxgIwduxYpkyZwr59+1AUhcjIoqdElmQuhBBGFL1i8pKVlUVKSkqhJSsrq9BxIyMjmTp1Ku7u7sDvU554enpSp04dHB0d8ff3JyYmhmvXrpGdnU2LFi0ACAwMJCYmptDx/kxq5kIIYawY5ZPVq1cTERFRaHtISAihoaEFts2YMaPAekZGBm5ufzxNzN3dnfT09ELb3dzcSE9PLzIWSeZCCGGkOM+mCA4OJiAgoNB2rbboGUX1en2B59gqioKDg8MjtxdFkrkQQhgrRjLXarUmJe6HqVGjBpmZmYb1zMxM3N3dC22/ceOGoTTzV6RmLoQQRhS96Ys5mjdvTmJiIsnJyeh0OqKioujYsSO1a9fGxcWF48ePA7Br1y46duxY5PGkZy6EEEaUokcBWoSLiwuzZ88mNDSUnJwcvLy88PHxAWDevHlMmjSJe/fu0aRJEwYMGFDk8az2cApLkodT2AZ5OIXtkIdTPFrGP7xM3tf961iz2rIkm+iZ33hwV+0QLK5ava5qh2BxjuU0aodgFfl2mPjKfA9OReaWT9RiE8lcCCFKjVL0yJGySJK5EEIYkZ65EELYAX2+9MyFEMLmKVJmEUII2ydlFiGEsAOKXnrmQghh88r+nTcPJ8lcCCGMSM9cCCHsgF4nyVwIIWye9MyFEMIOyNBEIYSwAzI0UQgh7IDeRnvmJj2c4vr168TGxqLT6UhNTbV2TEIIoRpFcTB5KUuKTOaHDx+mb9++fPTRR9y8eRM/Pz8OHjxYGrEJIUSp0+scTF7KkiKT+WeffUZkZCRarRZ3d3c2bNjA4sWLSyM2IYQodYreweSlLCmyZq7T6Qo8TPSZZ54x6UnRQghhi+y2Zl6hQgVSU1MNCfzYsWO4uLhYPbDSNmNWOGfOHeFIfBRH4qNYtdr2v30826QRUXvX8+13uzn8zU5atHhO7ZAswh7PKygogB+P7uPoDzEc/vcOWrZspnZIFuHb/R+cOH6AMwnfsGnjMh57rJLaIRXJWjXzXbt24efnh5+fH3PmzAEgLi4Of39/vL29WbBggVlxF/kM0BMnThAeHk5mZiYNGjQgKSmJJUuW0Lp1a7MaLg5txfpWb+Pgoa2ET5jJ0R9OWL0twOrfbipUKM9/Tv+bkPcncGD/YXz9uvDRx+N4saW3Vdu1NjXOKzs/12rHBmjUsD7790fStp0v169n4NPtFZZEzKJhw7ZWa7M0nmtarVoVTv3n33Ts1IuLFxOZNTOcSpUqEToi3Krt5pv5DNBT9fxN3rdZ0h6T9nvw4AFeXl7ExMSg1WoJCgpi2LBhTJs2jbVr11KzZk3ee+89BgwYgJeX6c8gNVZkmaVly5ZERkby008/odfrad68OVWqVCnywAcPHiQtLQ0vLy/q1q1r2L5582beeOONEgVrLc7OzjRr3oRRo4fwZH1PLv6SyITx00lJsd2RO53/0YHEy1c4sP8wANH/Okhy0lV1g7IAezyvnNxchg0bx/XrGQAcP3GKGtXdcHJyIi8vT+XoSq5rVy+OHTvJxYuJAPzfsjWcOHbA6sncXDq9SYP8indMnQ69Xs+DBw9wdXUlPz+fSpUq4enpSZ06dQDw9/cnJiamxMm8yKjPnDnD1atXqVatGu7u7qSlpXHmzJm/fM+8efNYt24dSUlJBAUFsWvXLsNrmzZtKlGg1lSzpjvfxMbz8bT5tGvdnR9//ImNkcvUDsssDRo8SUZGJhGfzeLwNzvZtWcNjo62f1uBPZ5XcnIKe2MOGdbnzp1CVNQBm07kAHU8anHVqEOUkpLG449ry3ypRVFMX7KyskhJSSm0ZGVlFThmpUqVGDlyJN27d8fLy4vatWuTkZGBm5ubYR93d3fS09NLHHeR/wpCQ0MNP+fl5ZGZmclzzz3H1q1bH/me2NhYduzYgaOjI/3792fQoEE4OzvTvXt3iqjqqCI5OYU+gYMM64sXLmfc+BA8PT1ITk5RMbKSc3JypKt3J3r4vsXxYyfx9evClu0reO6ZjuTmWrdsYE32el4Arq4V+HL5fDw8auH/an+1wzFbuXLlHvrvXafTqRCN6YpzAXT16tVEREQU2h4SElIgd547d45t27bx73//m8cee4wPPviApKSkAuVWRVHMKr8WmcwPHTpUYP2HH35gz56/rhMZB1WvXj2WLVvG22+/TZUqVcrkSJgmzzWmadPGbNq407DNwcGBvLx89YIyU1paOhfOX+L4sZPA7+WIJZ/NpN6Tdbhw/pLK0ZWcvZ5XnTq12L5tFefOXcS72xtkZ2erHZLZrly9RuvWzxvWa9euwa1bt7l//4GKURWtOBc2g4ODCQgIKLRdq9UWWD9y5Ajt2rWjatWqAAQGBrJixQo0Go1hn8zMzAIjB4ur2MWhNm3aFFlm8fHxoX///pw6dQqAhg0bsmjRIkaNGsWVK1dKFqkV6fV65nwyFU9PDwAGv9uPMwnnSE29rnJkJXdgfyyenh6GkR4vtX8RRcHm68v2eF6VKlXkwP5Idu7aS/8Bw+0ikQMcOBBLm9YtadDgSQDeG9Kf3Xv2qxxV0fSKg8mLVqvFw8Oj0PLnZN64cWPi4uK4f/8+iqJw6NAhmjdvTmJiIsnJyeh0OqKioujYsWOJ4y6yZ26cuBVFISEhochftpCQEFq1akXFihUN21q1asX27dtZuXJliYO1lrM/X2DcBx+yeetyNOU0XEu9zqCBo9QOyywZGTd4M2gony74CNeKruTm5NLvzWHk5Nh2KcIez2vYsIHUretBz1d96Pmqj2G7T/e+3Lp1R73AzJSZeZPB7/6TzZu+wNnZicuXkhk4aKTaYRXJGoXgl19+mZ9//pnAwECcnJxo2rQpoaGhtG/fntDQUHJycvDy8sLHx6fogz1CkUMTO3fu/MfODg5UrVqVMWPG0KZNmxI3WlylMTSxtJXFcpN4OGsPTVRDaQxNVIu5QxO/q9HH5H3bX3/0tcPSVmTPPDw8nC5dupRGLEIIoTpb/TNXZM3c3LuShBDClig4mLyUJUX2zBs1asTnn3/OCy+8gKurq2F7kyZNrBqYEEKoQV/2Rk+bpMhkvm/fPk6ePMmWLVsM2x48eEB8fLxVAxNCCDXoy1iP21SPTOZ37twBoEGDBqxZs8YwdjwvL49+/fqVVnxCCFGqylr5xFSPTOZjxozhu+++w8HBgXbt2hm2azQaunXrVirBCSFEadPZWzJfsWIFABMmTGDWrFmlFpAQQqjJVkezFFkzl0QuhPg7sdtkLoQQfyd2VzMXQoi/ozL2aE+TSTIXQggjdncBVAgh/o6kZi6EEHZAb6OT4EkyF0IIIzZ6N78kcyGEMCZlFiGEsAMymkUIIeyAjGaxIp1iq198Hs3RQVP0TjYmX1+2n7peUk2e8FQ7BIs7fTNR7RDKLOmZCyGEHbDVrmORTxoSQoi/E6UYS3EcOnSIwMBAunfvzvTp0wGIi4vD398fb29vs5/qJslcCCGM6B1MX0x19epVpk6dytKlS9m9ezc///wzsbGxhIeHs3TpUqKjo0lISCA2NrbEcUuZRQghjBSnzJKVlUVWVlah7VqtFq1Wa1g/cOAAvr6+1KhRA/j92crJycl4enpSp04dAPz9/YmJicHLy6tEcUsyF0III7pi9LhXr15NREREoe0hISGEhoYa1pOTk3FycmLo0KGkpaXRqVMnGjZsiJubm2Efd3d30tPTSxy3JHMhhDBSnJ55cHAwAQEBhbYb98oBdDodx44dY+3atbi6ujJs2DDKly+Pg9HUAf97NGdJSTIXQggjxUnmfy6nPEq1atVo164dVapUAaBLly7ExMSg0fwxRDkzMxN3d/fihmsgF0CFEMKINUazvPLKKxw5coSsrCx0Oh3ffvstPj4+JCYmkpycjE6nIyoqio4dO5Y4bumZCyGEEWvcNNS8eXMGDx7Mm2++SV5eHu3btycoKIj69esTGhpKTk4OXl5e+Pj4lLgNB0VRyvwkYRVd66kdgsU5lpM7QG3F0497qB2CxdnzHaB5udfMev+ndfuZvO+YK+vMasuSpGcuhBBGynzv9hEkmQshhBGZm0UIIeyArc7NIslcCCGMSJlFCCHsgN5G07kkcyGEMGKrY7LkpiEjPfy9uZ6eoHYYFvNsk0ZE7V3Pt9/t5vA3O2nR4jm1Q7IYe/isfHt7s+ngV2w8sIpVuz/nmeZPG16rXsudmBM7qFzlcRUjtJyVKxYyevR7aodhEn0xlrJEkvl/PfVUPWbODDdrboSypEKF8uzYtZpFC5bTof2rzJ0TwfKV89UOyyLs4bPyfKoOIye/T8ibYwjq+jZfLlzNvBUzAfB7zYcvd0TgXtOtiKOUfY0bN2D/vkgCA/3UDsVk1pgCtzRIMuf3xLdi5ULCwqarHYrFdP5HBxIvX+HA/sMARP/rIAP7h/71m2yAvXxWuTl5fDxmDjcybgLw88lzVHOrQo3a1XnFpwPDg8aoHKFlDBs6kJWrNrBtW5TaoZhMj2LyUpZYrWaelJREhQoVqF69Olu2bOH8+fO0bNkSX19fazVZYkuWzGTlivUknD6ndigW06DBk2RkZBLx2Syea/oMd+9mMWXSHLXDMpu9fFZpKddJS7luWB/zUSix+49w/Vo6H7wzUcXILGvkqEkAdO1Ssjm61VC2UrTprJLMv/rqK9auXYter6dt27akpaXRtWtXtm3bRmJiIsOHD7dGsyXy7pB+5Ot0rFmzhbp17ee2bScnR7p6d6KH71scP3YSX78ubNm+guee6Uhubq7a4ZWIPX5W5SuU56NFE6lRy53hb9pHb9zW5dtoOrdKmWXbtm1ER0ezbt06YmJiWLZsGW+99Raff/45+/bts0aTJdavXx9atWxG/PfRbN+xigoVyhP/fTQ1apZ8KsqyIC0tnQvnL3H82Eng9zKLRlOOek/WUTmykrO3z6pG7ep8tef/0Ot0DOkTyr2se2qHJLDeM0CtzSo9c71ej7OzM7Vr12bQoEG4uLgYXtPpytbAH6+OvQw/163rwY/H9tGubdkrBRXXgf2xzJgZTosWz/Gf/yTwUvsXURRITrqqdmglZk+flWvFCnyxbQlRkXv5Yv4qtcMRRsraKBVTWSWZe3t7069fP9asWWN4dNK5c+eYNGkS3bt3t0aT4k8yMm7wZtBQPl3wEa4VXcnNyaXfm8PIybHNEou9eWNQb2p6VOeV7h15pfsfc1gPfX0kd28XfqakKD1l7cKmqaw2Be6PP/7Iiy++aFi/fPkyV69eLdHDSmUKXNsgU+DaDpkC99FG1+tr8r4LkjaZ1ZYlWW00i3EiB6hfvz7169e3VnNCCGERUmYRQgg7oLPRMoskcyGEMGKrNXO5A1QIIYxYe2jinDlzCAsLAyAuLg5/f3+8vb1ZsGCBWXFLMhdCCCPWvJ0/Pj6eHTt2AJCdnU14eDhLly4lOjqahIQEYmNjSxy3JHMhhDBirVkT79y5w4IFCxg6dCgAp06dwtPTkzp16uDo6Ii/vz8xMTEljltq5kIIYUQpRo87KyuLrKzC9wVotVq0Wm2BbVOmTGH06NGkpaUBkJGRgZvbHzNjuru7k56eXsKoJZkLIUQBxRnNsnr1aiIiIgptDwkJMdwwCbBlyxZq1qxJu3bt2L59O/D7nfLG0zgrimLWtM6SzIUQwkhxyifBwcEEBAQU2v7nXnl0dDSZmZn07NmTu3fvcv/+fa5du4ZG88fNg5mZmbi7l3yeIUnmQghhRF+Mm+IfVk55mFWr/ph/Z/v27Rw9epSPPvoIb29vkpOT8fDwICoqit69e5coZpBkLoQQBZTWKHMXFxdmz55NaGgoOTk5eHl54ePjU+LjWW1uFkuSuVlsg8zNYjtkbpZHe9OzcNnkUTYk7zCrLUuSnrkQQhiR2/mFEMIO2Ort/JLMhRDCSHHGmZclksyFEMKITIErhBB2wAbGhDyUTSRzjYP9TSHzW2622iEIE9njyA+NHY6mshSpmQshhB2Q0SxCCGEHpGcuhBB2QGrmQghhB2Q0ixBC2AEZZy6EEHZAauZCCGEHdIptFlokmQshhBEpswghhB0ozsMpyhJJ5kIIYcQ2U7kkcyGEKEAugAohhB2w1Qug9jeDlRBCmEGPYvJSHBEREfj5+eHn58fcuXMBiIuLw9/fH29vbxYsWGBW3JLMhRDCiFKM/0wVFxfHkSNH2LFjBzt37uTMmTNERUURHh7O0qVLiY6OJiEhgdjY2BLHLclcCCGMKIpi8mIqNzc3wsLCcHZ2xsnJiaeeeoqkpCQ8PT2pU6cOjo6O+Pv7ExMTU+K4pWYuhBBGilM+ycrKIisrq9B2rVaLVqs1rDds2NDwc1JSEnv37qVfv364ubkZtru7u5Oenl7CqCWZCyFEAcXpca9evZqIiIhC20NCQggNDS20/ZdffuG9995j3LhxaDQakpKSCrTr4OBQophBkrnBjFnh9Arw5fbtOwD8cuEybwePUDcoM/l2/wfTp4fh4uLC6dNneXfIGH799Z7aYZnNXs8LYOWKhZxOOMuCBcvUDsUihg4NZsiQ/iiKwuXLybz//ngyM2+qHdZf0hVj3sTg4GACAgIKbTfulf/P8ePHGTFiBOHh4fj5+XH06FEyMzMNr2dmZuLu7l6yoJGauUGbNi15O3gEL7frwcvteth8Iq9WrQpfLp/P628MoclzHUlMTGbmjHC1wzKbvZ5X48YN2L8vksBAP7VDsZjnn2/K6NFD6NQpgFatunLxYiJTp36gdlhF0iuKyYtWq8XDw6PQ8udknpaWxvDhw5k3bx5+fr9/xs2bNycxMZHk5GR0Oh1RUVF07NixxHGXSjKfPXt2aTRTYs7OzjRr3oRRo4cQf3Qva9cvxcOjltphmaVrVy+OHTvJxYu/P7/y/5at4c2gwj0IW2Ov5zVs6EBWrtrAtm1RaodiMT/9dJomTbzIyvoVFxcXateuwa1bt9UOq0jWGM2yYsUKcnJymD17Nj179qRnz55s376d2bNnExoaiq+vL/Xr18fHx6fEcVu8zDJhwoRC2w4dOsTdu3cBmDVrlqWbNFvNmu58ExvPx9Pmc/bnC4wY9S4bI5fR4SV/tUMrsToetbiakmpYT0lJ4/HHtTz2WCWbLknY63mNHDUJgK5dvFSOxLLy8/Px9/fm88/nkpOTy0cffap2SEWyxtwskyZNYtKkSQ99bffu3RZpw+I988qVK3P48GEaN25M69atad26Na6uroafy6Lk5BT6BA7i7M8XAFi8cDlPPlkXT08PlSMruXLlyj30Qo5Op1MhGsux1/OyZ3v27MfDowUzZiwgKmqdWRf5SoM1eualweLJfPz48cyfP5/o6Ghq1apFQEAAjz/+OAEBAQ+9UFAWNHmuMX2DehXY5uDgQF5evjoBWcCVq9eoVau6Yf1/X3Hv33+gYlTms9fzskf163vy0ksvGta/+mozdevW5oknHlcxqqIVp2ZellilZt6uXTuWLVvGhg0bmDNnTpnvNen1euZ8MtXQEx/8bj/OJJwjNfW6ypGV3IEDsbRp3ZIGDZ4E4L0h/dm9Z7/KUZnPXs/LHtWsWZ01ayKoWvUJAIKCAjhz5jy3bt1RN7Ai6BS9yUtZYrWhiZUrV2bRokVs2bKF8+fPW6sZizj78wXGffAhm7cuR1NOw7XU6wwaOErtsMySmXmTwe/+k82bvsDZ2YnLl5IZOGik2mGZzV7Pyx59991R5sxZwv79keTn55OWls7rr7+rdlhFKmvlE1M5KMUZIa8SbcX6aodgcffzctQOQZiobFd4S0ZTTqN2CFaTnX3FrPc/WbW5yfsm3jxpVluWJDcNCSGEEZnPXAgh7IANFCseSpK5EEIYKWsXNk0lyVwIIYyUtSGHppJkLoQQRmx1NIskcyGEMCI1cyGEsAMymkUIIeyA9MyFEMIO6PQymkUIIWyelFmEEMIOSJlFCCHsgIwzF0IIOyDjzIUQwg7Yas+8VB7oLIQQtkKv6E1eimPPnj34+vri7e3N+vXrLR639MyFEMKINS6Apqens2DBArZv346zszN9+/alTZs2NGjQwGJtSDIXQggjxUnmWVlZZGVlFdqu1WrRarWG9bi4ONq2bUvlypUB6NatGzExMYSEhJgd7//YRDLP+u2y2iEIIf4m8nKvmbzvkiVLiIiIKLQ9JCSE0NBQw3pGRgZubm6GdXd3d06dOmVeoH9iE8lcCCHKouDgYAICAgptN+6Vw+8PjXdw+OMBhIqiFFi3BEnmQghRQn8upzxKjRo1OHbsmGE9MzMTd3d3i8Yio1mEEMLKXnrpJeLj47l16xYPHjxg//79dOzY0aJtSM9cCCGsrHr16owePZoBAwaQl5dHnz59aNasmUXbcFBsdSICIYQQBlJmEUIIOyDJXAgh7IAkcyGEsAOSzIUQwg5IMv8va0+Co5Z79+7Ro0cPUlJS1A7FYiIiIvDz88PPz4+5c+eqHY7FLFq0CF9fX/z8/Fi1apXa4VjUnDlzCAsLUzsMuybJnD8mwdmwYQM7d+5k8+bNXLx4Ue2wzHby5EmCgoJISkpSOxSLiYuL48iRI+zYsYOdO3dy5swZDhw4oHZYZjt69Cjff/89u3fvZtu2baxdu5bLl+1jGov4+Hh27Nihdhh2T5I5BSfBcXV1NUyCY+siIyOZOnWqxe80U5ObmxthYWE4Ozvj5OTEU089RWpqqtphma1169asWbMGR0dHbt68iU6nw9XVVe2wzHbnzh0WLFjA0KFD1Q7F7slNQ5TOJDhqmDFjhtohWFzDhg0NPyclJbF37142btyoYkSW4+TkxOLFi1m5ciU+Pj5Ur15d7ZDMNmXKFEaPHk1aWpraodg96ZlTOpPgCMv65ZdfGDRoEOPGjaNevXpqh2MxI0aMID4+nrS0NCIjI9UOxyxbtmyhZs2atGvXTu1Q/hakZ07pTIIjLOf48eOMGDGC8PBw/Pz81A7HIi5dukRubi7PPPMMFSpUwNvbm/Pnz6sdllmio6PJzMykZ8+e3L17l/v37zNz5kzCw8PVDs0uSTLn90lwlixZwq1bt6hQoQL79+/n448/Vjss8RBpaWkMHz6cBQsW2FWPLyUlhcWLFxtKRl9//TW9e/dWOSrzGI/I2b59O0ePHpVEbkWSzCmdSXCEZaxYsYKcnBxmz55t2Na3b1+CgoJUjMp8Xl5enDp1il69eqHRaPD29rabbx2idMhEW0IIYQfkAqgQQtgBSeZCCGEHJJkLIYQdkGQuhBB2QJK5EELYAUnmwi48//zzpKSkcPr0aUaMGPGX+546dYopU6aUUmRClA5J5sKuNG3alMWLF//lPhcvXiQ9Pb2UIhKidMhNQ6LU/fDDD8ybN49atWpx+fJlypcvz+zZs1m+fDl37tzh6tWrdOrUiZEjRzJv3jx+/PFHdDodzz77LJMmTaJSpUocO3aMjz/+GAcHB5o2bYperzcc++OPPyYqKorffvuN6dOnc+LECTQaDV26dCEoKIjFixfz66+/MmHCBGbNmqXy/w0hLEN65kIVCQkJ9O/fnz179hAYGMjYsWMByM7O5l//+hdjx47liy++QKPRsH37dnbv3o27uzvz5s0jNzeXkSNHEhYWxs6dO2nTpg3Z2dmF2li8eDE5OTlER0ezc+dOTpw4wZUrVxgxYgQvvPCCJHJhVySZC1U0btyYF154AYDevXtz9uxZ7ty5Q6tWrQz7HD58mEOHDtGrVy969uzJwYMHuXTpEhcuXMDR0dEwN0uPHj2oWLFioTbi4uLo06cPGo0GZ2dn1q1bR5s2bUrnBIUoZVJmEarQaDSFtpUrV67AAxn0ej3h4eF4eXkB8Ntvv5GTk0Nqaip/noXC0bHwr7Kjo2OBqYzT0tIoX768pU5BiDJFeuZCFefOnePcuXMAbN68meeffx6tVltgn5dffpn169eTm5uLXq9n8uTJzJ8/n6effhpFUYiNjQV+n2Hw7t27hdpo164dO3bsQK/Xk5uby4gRI/jxxx/RaDTk5+db/ySFKEWSzIUqqlWrxsKFC/H39+fgwYMPfTDz+++/T+3atQkICMDX1xdFUQgLC8PJyYnPPvuMRYsW0bNnTw4cOEDVqlULvT8kJAQnJyd69uxJr1698PLywtvbmxYtWnD16lVCQkJK41SFKBUya6IodcYjToQQliE9cyGEsAPSMxdCCDsgPXMhhLADksyFEMIOSDIXQgg7IMlcCCHsgCRzIYSwA5LMhRDCDvw//d0EvHrfKG0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = confusion_matrix(Y_validation,predictions) #绘制混淆矩阵\n",
    "\n",
    "\n",
    "sns.set()\n",
    "f,ax=plt.subplots()\n",
    "\n",
    "\n",
    "sns.heatmap(confusion,annot=True,ax=ax) #画热力图\n",
    "\n",
    "ax.set_title('confusion matrix') #标题\n",
    "ax.set_xlabel('predict') #x轴\n",
    "ax.set_ylabel('true') #y轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1475b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集成学习模型\n",
      "0.8274111675126904\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  1   6   3   1   0]\n",
      " [  6   6   1   6   0]\n",
      " [  2   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        49\n",
      "           1       0.85      0.97      0.91       115\n",
      "           2       0.75      0.27      0.40        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.65      0.48      0.52       197\n",
      "weighted avg       0.81      0.83      0.80       197\n",
      "\n",
      "adaboost模型\n",
      "0.8477157360406091\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0  11   0   0   0]\n",
      " [  0  19   0   0   0]\n",
      " [  0   0   0   0   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.79      1.00      0.88       115\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00        19\n",
      "           4       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.56      0.60      0.58       197\n",
      "weighted avg       0.73      0.85      0.78       197\n",
      "\n",
      "svm模型\n",
      "0.8324873096446701\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   6   4   1   0]\n",
      " [  3   8   2   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        49\n",
      "           1       0.83      0.97      0.90       115\n",
      "           2       0.67      0.36      0.47        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.64      0.50      0.54       197\n",
      "weighted avg       0.82      0.83      0.81       197\n",
      "\n",
      "随机森林模型\n",
      "0.8071065989847716\n",
      "[[ 44   5   0   0   0]\n",
      " [  1 114   0   0   0]\n",
      " [  3   8   0   0   0]\n",
      " [  9   9   0   1   0]\n",
      " [  2   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.81        49\n",
      "           1       0.83      0.99      0.90       115\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       1.00      0.05      0.10        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81       197\n",
      "   macro avg       0.52      0.39      0.36       197\n",
      "weighted avg       0.77      0.81      0.74       197\n",
      "\n",
      "xgboost模型\n",
      "[09:31:10] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59496\teval-mlogloss:1.59492\n",
      "[2000]\ttrain-mlogloss:0.27936\teval-mlogloss:0.28609\n",
      "[3136]\ttrain-mlogloss:0.27666\teval-mlogloss:0.28314\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.93      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.90      0.95      0.92        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.77      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "++++++++++++++\n",
      "0.8426395939086294\n",
      "[[ 41   8   0   0   0]\n",
      " [  2 113   0   0   0]\n",
      " [  1   4   6   0   0]\n",
      " [  5   5   3   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        49\n",
      "           1       0.86      0.98      0.91       115\n",
      "           2       0.67      0.55      0.60        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.67      0.54      0.56       197\n",
      "weighted avg       0.84      0.84      0.82       197\n",
      "\n",
      "----------------------\n",
      "集成学习模型\n",
      "0.8527918781725888\n",
      "[[ 44   5   0   0   0]\n",
      " [  3 111   1   0   0]\n",
      " [  0   4   7   0   0]\n",
      " [  4   7   2   6   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87        49\n",
      "           1       0.87      0.97      0.91       115\n",
      "           2       0.64      0.64      0.64        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.67      0.56      0.58       197\n",
      "weighted avg       0.85      0.85      0.83       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report  #将主要分类指标以文本输出\n",
    "from sklearn.metrics import confusion_matrix #计算混淆矩阵，主要来评估分类的准确性\n",
    "from sklearn.metrics import accuracy_score #计算精度得分\n",
    "from imblearn.over_sampling import SMOTE # 使用imlbearn库中上采样方法中的SMOTE接口\n",
    "from collections import Counter # 查看所生成的样本类别分布，0和1样本比例9比1，属于类别不平衡数据\n",
    "from sklearn.datasets import make_classification # 使用sklearn的make_classification生成不平衡数据样本\n",
    "from imblearn.under_sampling import RandomUnderSampler # 引入随机欠采样\n",
    "\n",
    "class EC():\n",
    "    \"\"\"\n",
    "        EC\n",
    "        Ensemble Classifier\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "                    self,\n",
    "                    svm_num=1,\n",
    "                    rf_num=1\n",
    "                ):\n",
    "        \"\"\"\n",
    "            Initializes the SBBTree.\n",
    "            Args:\n",
    "              svm_num : number of svm.\n",
    "              rf_num : number of rf.\n",
    "        \"\"\"\n",
    "        self.svm_num = svm_num\n",
    "        self.rf_num = rf_num\n",
    "        self.svm_model = []\n",
    "        self.rf_model = []\n",
    "        self.model_first = []\n",
    "        self.model_second = []\n",
    "        self.mistake_X_all = []\n",
    "        self.mistake_y_all = [] # mistake_data\n",
    "\n",
    "    def svm_fit(self, X, y):\n",
    "        \"\"\" fit model. \"\"\"\n",
    "        # 按比例欠采样,test_size后序可以设置变动,使用分层采样，每次采样样本都不会重复\n",
    "        self.SSS = StratifiedShuffleSplit(n_splits=self.svm_num, test_size=0.1, random_state=0)\n",
    "        # 按相同数量对训练集划分以构建评估集\n",
    "        # self.SK = StratifiedShuffleSplit(n_splits=self.svm_num, test_size=0.2, random_state=1)\n",
    "        self.SK = StratifiedKFold(n_splits=self.svm_num, shuffle=True, random_state=0)\n",
    "\n",
    "        for sss_split, sk_split in zip(self.SSS.split(X, y), self.SK.split(X, y)):\n",
    "            train_index, test_index = sss_split[0], sss_split[1]\n",
    "            sk_index, sk_val_index = sk_split[0], sk_split[1]\n",
    "\n",
    "            # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            sk_val_X_test = X[sk_val_index]\n",
    "            sk_val_y_test = y[sk_val_index]\n",
    "\n",
    "            # 进行过采样\n",
    "            smo = SMOTE(random_state=42)\n",
    "            X_smo, y_smo = smo.fit_resample(X_train, y_train)\n",
    "            # print(Counter(y_smo))\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('Standardization', StandardScaler()),\n",
    "                ('svc', SVC())\n",
    "            ])\n",
    "\n",
    "            tuned_parameters = {\n",
    "                'svc__kernel': ['rbf'],  # 'sigmoid', 'precomputed', 'poly', 'linear'\n",
    "                # 'svc__gamma': ['scale', 'auto'],\n",
    "            }\n",
    "            scores = ['f1_micro']\n",
    "            for score in scores:\n",
    "                # print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "                svc = GridSearchCV(pipeline, tuned_parameters, scoring='%s' % score)\n",
    "                svc.fit(X_smo, y_smo)\n",
    "                # print(\"Best parameters set found on development set:\")\n",
    "                # print(svc.best_params_)\n",
    "\n",
    "                self.svm_model.append(svc)\n",
    "\n",
    "            pred_y = svc.predict(sk_val_X_test)\n",
    "            index = np.arange(0, len(sk_val_y_test))\n",
    "            mistake_index = index[pred_y != sk_val_y_test]\n",
    "\n",
    "            # 找出第一阶段分类器分类错误的数据\n",
    "            for i in mistake_index:\n",
    "                self.mistake_X_all.extend([sk_val_X_test[i]])\n",
    "                self.mistake_y_all.extend([sk_val_y_test[i]])\n",
    "        return self.mistake_X_all, self.mistake_y_all\n",
    "\n",
    "\n",
    "    def rf_fit(self, X, y):\n",
    "        \"\"\" fit model. \"\"\"\n",
    "        for i in range(self.rf_num):\n",
    "            X_resampled, _, y_resampled, _ = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "            rf = RandomForestClassifier(n_jobs=-1)\n",
    "            tuned_parameters = {\n",
    "                'n_estimators': [50], # 50, 100, 200\n",
    "                # 'criterion': ['gini', 'entropy'],\n",
    "                # 'max_depth': [2, 5],\n",
    "                # 'max_features': ['log2', 'sqrt', 'int'],\n",
    "                # 'bootstrap': [True, False],\n",
    "                # 'warm_start': [True, False]\n",
    "            }\n",
    "            scores = ['f1_micro']\n",
    "            for score in scores:\n",
    "                # print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "                # rf = GridSearchCV(rf, tuned_parameters, cv=5, scoring='%s' % score)\n",
    "                rf.fit(X_resampled, y_resampled)\n",
    "                # print(\"Best parameters set found on development set:\")\n",
    "                # print(rf.best_params_)\n",
    "\n",
    "                self.rf_model.append(rf)\n",
    "\n",
    "\n",
    "    def second_fit(self, X_train, y_train):\n",
    "        self.model_first = self.svm_model\n",
    "        self.model_first.extend(self.rf_model)\n",
    "        X_second, _, y_second, _ = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "        test_pred = np.zeros((X_second.shape[0], len(self.model_first)))\n",
    "        for sn,clf in enumerate(self.model_first):\n",
    "            pred = clf.predict(X_second)\n",
    "            test_pred[:, sn] = pred\n",
    "        X_second = np.hstack((np.array(X_second), np.array(test_pred)))\n",
    "\n",
    "        # 第二阶段选择随机森林\n",
    "        # rf = RandomForestClassifier(n_jobs=-1)\n",
    "        # tuned_parameters = {\n",
    "        #     'n_estimators': [50, 100, 200],  #\n",
    "        #     'criterion': ['gini', 'entropy'],\n",
    "        #     # 'max_depth': [2, 5],\n",
    "        #     # 'max_features': ['log2', 'sqrt', 'int'],\n",
    "        #     # 'bootstrap': [True, False],\n",
    "        #     # 'warm_start': [True, False]\n",
    "        # }\n",
    "        # scores = ['f1_micro']\n",
    "        # for score in scores:\n",
    "        #     # print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        #     rf = GridSearchCV(rf, tuned_parameters, scoring='%s' % score)\n",
    "        #     rf.fit(X_second, y_second)\n",
    "        #     # print(\"Best parameters set found on development set:\")\n",
    "        #     # print(rf.best_params_)\n",
    "        #     self.model_second.append(rf)\n",
    "        pipeline = Pipeline([\n",
    "            ('Standardization', StandardScaler()),\n",
    "            ('svc', SVC())\n",
    "        ])\n",
    "        pipeline.fit(X_second, y_second)\n",
    "        self.model_second.append(pipeline)\n",
    "\n",
    "    def model_test(self, X_test):\n",
    "        \"\"\" predict test data. \"\"\"\n",
    "        test_pred = np.zeros((X_test.shape[0], len(self.model_first)))\n",
    "        for sn, clf in enumerate(self.model_first):\n",
    "            pred = clf.predict(X_test)\n",
    "            test_pred[:, sn] = pred\n",
    "        X_test = np.hstack((np.array(X_test), np.array(test_pred)))\n",
    "\n",
    "        for clf in self.model_second:\n",
    "            return clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    def pred(self, y_test, predictions):\n",
    "        predictions = np.rint(predictions)\n",
    "        print(accuracy_score(y_test, predictions))  # 验证集精度得分\n",
    "        print(confusion_matrix(y_test, predictions))  # 混淆矩阵\n",
    "        print(classification_report(y_test, predictions))  # 分类预测报告\n",
    "\n",
    "    def model_adaboost(self, X_train, y_train, X_test):\n",
    "        clf = AdaBoostClassifier(n_estimators=10)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        return clf.predict(X_test)\n",
    "\n",
    "    def model_svm(self, X_train, y_train, X_test):\n",
    "        pipeline = Pipeline([\n",
    "            ('Standardization', StandardScaler()),\n",
    "            ('svc', SVC())\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        return pipeline.predict(X_test)\n",
    "\n",
    "    def model_randomforest(self, X_train, y_train, X_test):\n",
    "        clf = RandomForestClassifier(n_estimators=10, max_depth=3, min_samples_split=12, random_state=0)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        return clf.predict(X_test)\n",
    "\n",
    "    def model_xgboost(self, X_train, y_train, X_test1, y_test1):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=0, stratify=y_train)\n",
    "        clf = xgboost\n",
    "        train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1, silent=True)\n",
    "        test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1, silent=True)\n",
    "        z = clf.DMatrix(X_test1, label=y_test1, missing=-1, silent=True)\n",
    "        params = {'booster': 'gbtree',\n",
    "                  'objective': 'multi:softprob',\n",
    "                  'n_estimators': 100,\n",
    "                  'eval_metric': 'mlogloss',\n",
    "                  'gamma': 1,\n",
    "                  'min_child_weight': 1.5,\n",
    "                  'max_depth': 3,\n",
    "                  'lambda': 100,\n",
    "                  'subsample': 0.7,\n",
    "                  'colsample_bytree': 0.7,\n",
    "                  'colsample_bylevel': 0.7,\n",
    "                  'eta': 0.03,\n",
    "                  'tree_method': 'exact',\n",
    "                  'seed': 2017,\n",
    "                  \"num_class\": 5\n",
    "                  }\n",
    "\n",
    "        num_round = 10000\n",
    "        early_stopping_rounds = 100\n",
    "        watchlist = [(train_matrix, 'train'),\n",
    "                     (test_matrix, 'eval')\n",
    "                     ]\n",
    "\n",
    "        model = clf.train(params,\n",
    "                          train_matrix,\n",
    "                          num_boost_round=num_round,\n",
    "                          evals=watchlist,\n",
    "                          early_stopping_rounds=early_stopping_rounds,\n",
    "                          verbose_eval=2000\n",
    "                          )\n",
    "        pre = model.predict(z, ntree_limit=model.best_ntree_limit)\n",
    "        return pre\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    TEST CODE\n",
    "\"\"\"\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "# X, y = make_classification(n_samples=31200, n_features=25, n_classes=3, weights=[0.3, 0.67, 0.03],\\\n",
    "#                            n_redundant=20, n_clusters_per_class=2, n_informative=4, random_state=1)\n",
    "# # X, y = make_gaussian_quantiles(mean=None, cov=1.0, n_samples=1000, n_features=50, n_classes=2, shuffle=True, random_state=2)\n",
    "# # data = load_breast_cancer()\n",
    "# # X, y = data.data, data.target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify= y)\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "X = data.drop(['112'], axis = 1)\n",
    "X = data.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "\n",
    "# test 1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"集成学习模型\")\n",
    "model = EC(svm_num=2, rf_num=1)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred0=model.model_test(X_test)\n",
    "model.pred(y_test, pred0)\n",
    "\n",
    "print(\"adaboost模型\")\n",
    "model = EC()\n",
    "pred = model.model_adaboost(X_train, y_train, X_test)\n",
    "model.pred(y_test, pred)\n",
    "\n",
    "print(\"svm模型\")\n",
    "model = EC()\n",
    "pred = model.model_svm(X_train, y_train, X_test)\n",
    "model.pred(y_test, pred)\n",
    "\n",
    "print(\"随机森林模型\")\n",
    "model = EC()\n",
    "pred = model.model_randomforest(X_train, y_train, X_test)\n",
    "model.pred(y_test, pred)\n",
    "\n",
    "print(\"xgboost模型\")\n",
    "model = EC()\n",
    "pred = model.model_xgboost(X_train,  y_train, X_test, y_test)\n",
    "pred = np.argmax(pred, axis = 1)\n",
    "model.pred(y_test, pred)\n",
    "\n",
    "# # test 1\n",
    "print(\"++++++++++++++\")\n",
    "model = EC(svm_num=10, rf_num=10)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred1=model.model_test(X_test)\n",
    "model.pred(y_test, pred1)\n",
    "#\n",
    "# # test 2\n",
    "print(\"----------------------\")\n",
    "print(\"集成学习模型\")\n",
    "model = EC(svm_num=60, rf_num=15)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred1=model.model_test(X_test)\n",
    "model.pred(y_test, pred1)\n",
    "#\n",
    "# # test 3\n",
    "# print(\"------------------------\")\n",
    "# model = EC(svm_num=80, rf_num=20)\n",
    "# mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "# model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "# model.second_fit(X_train, y_train)\n",
    "# pred2=model.model_test(X_test)\n",
    "# model.pred(y_test, pred2)\n",
    "#\n",
    "# # test 4\n",
    "# model = EC(svm_num=80, rf_num=10)\n",
    "# mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "# model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "# model.second_fit(X_train, y_train)\n",
    "# pred3=model.model_test(X_test)\n",
    "# model.pred(y_test, pred3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred1, pos_label=2)\n",
    "# print('auc: ',metrics.auc(fpr, tpr))\n",
    "#\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred2, pos_label=2)\n",
    "# print('auc: ',metrics.auc(fpr, tpr))\n",
    "#\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred3, pos_label=2)\n",
    "# print('auc: ',metrics.auc(fpr, tpr))\n",
    "#\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test+1, pred4, pos_label=2)\n",
    "# print('auc: ',metrics.auc(fpr, tpr))\n",
    "\n",
    "\n",
    "# auc:  0.7281621243885396\n",
    "# auc:  0.7710471146419509\n",
    "# auc:  0.7894369046305492\n",
    "# auc:  0.8084519474787597"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925e380",
   "metadata": {},
   "source": [
    "### 消融实验\n",
    "- 去掉停留时长分布(1-17){左右端点均包括}\n",
    "- 去掉停留时段分布(18-41)\n",
    "- 去掉不同时段的停留频次分布(42-53)\n",
    "- 去掉停留点业务类型分布(54-55)\n",
    "- 去掉该区域临近道路类型(56->改为one-hot编码)\n",
    "- 去掉邻近POI类型分布(57-107)\n",
    "- 去掉停留区面积(108)\n",
    "- 去掉最后三列(109-111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48f2e2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>motorway</th>\n",
       "      <th>primary</th>\n",
       "      <th>residential</th>\n",
       "      <th>secondary</th>\n",
       "      <th>service</th>\n",
       "      <th>tertiary</th>\n",
       "      <th>trunk</th>\n",
       "      <th>unclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000021035</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.032986</td>\n",
       "      <td>0.063137</td>\n",
       "      <td>0.251272</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.12069</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>1.896552</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1         2    3     4     5         6         7         8  \\\n",
       "0  P000021035  0.24  0.313333  0.2  0.12  0.02  0.026667  0.006667  0.013333   \n",
       "\n",
       "          9        10        11   12        13        14        15        16  \\\n",
       "0  0.013333  0.026667  0.006667  0.0  0.013333  0.088733  0.032986  0.063137   \n",
       "\n",
       "         17        18        19        20        21        22    23    24  \\\n",
       "0  0.251272  0.026667  0.033333  0.026667  0.026667  0.026667  0.04  0.04   \n",
       "\n",
       "         25        26        27        28        29        30        31    32  \\\n",
       "0  0.046667  0.026667  0.046667  0.073333  0.053333  0.066667  0.046667  0.04   \n",
       "\n",
       "         33    34        35    36        37        38    39        40    41  \\\n",
       "0  0.073333  0.04  0.053333  0.06  0.046667  0.033333  0.02  0.013333  0.04   \n",
       "\n",
       "         42        43        44        45       46        47        48  \\\n",
       "0  0.034483  0.034483  0.034483  0.086207  0.12069  0.068966  0.189655   \n",
       "\n",
       "         49       50        51        52        53   54   55  57  58  59  60  \\\n",
       "0  0.086207  0.12069  0.068966  0.051724  0.103448  0.0  1.0   0   0   0   0   \n",
       "\n",
       "   61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   \n",
       "\n",
       "   99  100  101  102  103  104  105  106  107       108       109       110  \\\n",
       "0   0    0    0    0    0    0    0    3    0  0.005784  0.465517  1.896552   \n",
       "\n",
       "        111  112  motorway  primary  residential  secondary  service  \\\n",
       "0  0.293103    1         0        0            0          0        0   \n",
       "\n",
       "   tertiary  trunk  unclassified  \n",
       "0         0      0             1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbd03e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm模型\n",
      "0.8324873096446701\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   6   4   1   0]\n",
      " [  3   8   2   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        49\n",
      "           1       0.83      0.97      0.90       115\n",
      "           2       0.67      0.36      0.47        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.64      0.50      0.54       197\n",
      "weighted avg       0.82      0.83      0.81       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1 = data\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data_1['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print(\"svm模型\")\n",
    "model = EC()\n",
    "pred = model.model_svm(X_train, y_train, X_test)\n",
    "model.pred(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26a1ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉停留时长分布(1-17){左右端点均包括}\n",
      "svm模型\n",
      "0.8730964467005076\n",
      "[[ 43   6   0   0   0]\n",
      " [  1 114   0   0   0]\n",
      " [  0   5   5   1   0]\n",
      " [  0   8   1  10   0]\n",
      " [  0   0   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92        49\n",
      "           1       0.86      0.99      0.92       115\n",
      "           2       0.83      0.45      0.59        11\n",
      "           3       0.71      0.53      0.61        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       197\n",
      "   macro avg       0.68      0.57      0.61       197\n",
      "weighted avg       0.86      0.87      0.86       197\n",
      "\n",
      "######################################################\n",
      "去掉停留时段分布(18-41)\n",
      "svm模型\n",
      "0.8477157360406091\n",
      "[[ 42   7   0   0   0]\n",
      " [  2 113   0   0   0]\n",
      " [  0   7   4   0   0]\n",
      " [  3   5   3   8   0]\n",
      " [  1   0   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        49\n",
      "           1       0.86      0.98      0.91       115\n",
      "           2       0.57      0.36      0.44        11\n",
      "           3       0.80      0.42      0.55        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.62      0.52      0.56       197\n",
      "weighted avg       0.83      0.85      0.83       197\n",
      "\n",
      "######################################################\n",
      "去掉不同时段的停留频次分布(42-53)\n",
      "svm模型\n",
      "0.8426395939086294\n",
      "[[ 44   5   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   7   3   1   0]\n",
      " [  3   8   1   7   0]\n",
      " [  1   1   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       0.75      0.27      0.40        11\n",
      "           3       0.78      0.37      0.50        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.65      0.50      0.54       197\n",
      "weighted avg       0.82      0.84      0.82       197\n",
      "\n",
      "######################################################\n",
      "去掉停留点业务类型分布(54-55)\n",
      "svm模型\n",
      "0.8274111675126904\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   9   1   1   0]\n",
      " [  3   7   1   8   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        49\n",
      "           1       0.82      0.97      0.89       115\n",
      "           2       0.50      0.09      0.15        11\n",
      "           3       0.89      0.42      0.57        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.61      0.47      0.49       197\n",
      "weighted avg       0.80      0.83      0.80       197\n",
      "\n",
      "######################################################\n",
      "去掉邻近POI类型分布(57-107)\n",
      "svm模型\n",
      "0.8274111675126904\n",
      "[[ 44   5   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  2   6   2   1   0]\n",
      " [  8   3   2   6   0]\n",
      " [  2   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81        49\n",
      "           1       0.88      0.97      0.92       115\n",
      "           2       0.50      0.18      0.27        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.59      0.47      0.49       197\n",
      "weighted avg       0.81      0.83      0.80       197\n",
      "\n",
      "######################################################\n",
      "去掉停留区面积(108)\n",
      "svm模型\n",
      "0.8324873096446701\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   6   4   1   0]\n",
      " [  3   8   2   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        49\n",
      "           1       0.83      0.97      0.90       115\n",
      "           2       0.67      0.36      0.47        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.64      0.50      0.54       197\n",
      "weighted avg       0.82      0.83      0.81       197\n",
      "\n",
      "######################################################\n",
      "去掉最后三列(109-111)\n",
      "svm模型\n",
      "0.8020304568527918\n",
      "[[ 38  11   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  1   7   3   0   0]\n",
      " [  3   9   1   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79        49\n",
      "           1       0.79      0.97      0.87       115\n",
      "           2       0.75      0.27      0.40        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.80       197\n",
      "   macro avg       0.67      0.47      0.51       197\n",
      "weighted avg       0.80      0.80      0.77       197\n",
      "\n",
      "######################################################\n",
      "去掉该区域临近道路类型(56->改为one-hot编码)\n",
      "svm模型\n",
      "0.8324873096446701\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   5   4   2   0]\n",
      " [  3   8   2   6   0]\n",
      " [  1   1   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       0.67      0.36      0.47        11\n",
      "           3       0.67      0.32      0.43        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.61      0.50      0.53       197\n",
      "weighted avg       0.81      0.83      0.81       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去掉停留时长分布\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "del_first = [1, 18, 42, 54, 57, 108 , 109]\n",
    "del_end = [17, 41, 53, 55, 107, 108, 111]\n",
    "state = ['去掉停留时长分布(1-17){左右端点均包括}','去掉停留时段分布(18-41)','去掉不同时段的停留频次分布(42-53)',\\\n",
    "         '去掉停留点业务类型分布(54-55)','去掉邻近POI类型分布(57-107)',\\\n",
    "         '去掉停留区面积(108)','去掉最后三列(109-111)']\n",
    "state_num = 0\n",
    "for first, end in zip(del_first, del_end):\n",
    "    data_1 = data.drop(labels=[str(i) for i in range(first,end+1)], axis=1)\n",
    "    X = data_1.drop(['112'], axis = 1)\n",
    "    X = data_1.drop(['0'], axis = 1)\n",
    "    y = data_1['112']\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "#     print(\"集成学习模型\")\n",
    "#     model = EC(svm_num=2, rf_num=1)\n",
    "#     mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "#     model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "#     model.second_fit(X_train, y_train)\n",
    "#     pred0=model.model_test(X_test)\n",
    "#     model.pred(y_test, pred0)\n",
    "\n",
    "#     print(\"adaboost模型\")\n",
    "#     model = EC()\n",
    "#     pred = model.model_adaboost(X_train, y_train, X_test)\n",
    "#     model.pred(y_test, pred)\n",
    "    print(state[state_num])\n",
    "    state_num += 1\n",
    "    print(\"svm模型\")\n",
    "    model = EC()\n",
    "    pred = model.model_svm(X_train, y_train, X_test)\n",
    "    model.pred(y_test, pred)\n",
    "\n",
    "#     print(\"随机森林模型\")\n",
    "#     model = EC()\n",
    "#     pred = model.model_randomforest(X_train, y_train, X_test)\n",
    "#     model.pred(y_test, pred)\n",
    "    print(\"######################################################\")\n",
    "    \n",
    "data_1 = data.drop(labels=['motorway','primary','residential','secondary','service','tertiary','trunk','unclassified'], axis=1)\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print('去掉该区域临近道路类型(56->改为one-hot编码)')\n",
    "print(\"svm模型\")\n",
    "model = EC()\n",
    "pred = model.model_svm(X_train, y_train, X_test)\n",
    "model.pred(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866aa34",
   "metadata": {},
   "source": [
    "### 集成学习模型\n",
    "- svm_num=2, rf_num=1\n",
    "- svm_num=60, rf_num=10\n",
    "- svm_num=80, rf_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e99344f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉停留时长分布(1-17){左右端点均包括}\n",
      "集成学习模型\n",
      "0.8426395939086294\n",
      "[[ 41   8   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   6   4   1   0]\n",
      " [  2   7   1   9   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       0.80      0.36      0.50        11\n",
      "           3       0.75      0.47      0.58        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.66      0.53      0.57       197\n",
      "weighted avg       0.83      0.84      0.82       197\n",
      "\n",
      "######################################################\n",
      "去掉停留时段分布(18-41)\n",
      "集成学习模型\n",
      "0.8578680203045685\n",
      "[[ 41   8   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  3   3   2  11   0]\n",
      " [  1   1   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85        49\n",
      "           1       0.86      0.97      0.91       115\n",
      "           2       0.71      0.45      0.56        11\n",
      "           3       0.92      0.58      0.71        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.86       197\n",
      "   macro avg       0.67      0.57      0.60       197\n",
      "weighted avg       0.84      0.86      0.84       197\n",
      "\n",
      "######################################################\n",
      "去掉不同时段的停留频次分布(42-53)\n",
      "集成学习模型\n",
      "0.8426395939086294\n",
      "[[ 43   6   0   0   0]\n",
      " [  2 113   0   0   0]\n",
      " [  0   7   3   1   0]\n",
      " [  3   8   1   7   0]\n",
      " [  2   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        49\n",
      "           1       0.84      0.98      0.90       115\n",
      "           2       0.75      0.27      0.40        11\n",
      "           3       0.88      0.37      0.52        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.66      0.50      0.54       197\n",
      "weighted avg       0.83      0.84      0.82       197\n",
      "\n",
      "######################################################\n",
      "去掉停留点业务类型分布(54-55)\n",
      "集成学习模型\n",
      "0.8223350253807107\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   8   1   2   0]\n",
      " [  7   5   0   7   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       1.00      0.09      0.17        11\n",
      "           3       0.78      0.37      0.50        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82       197\n",
      "   macro avg       0.68      0.46      0.48       197\n",
      "weighted avg       0.82      0.82      0.79       197\n",
      "\n",
      "######################################################\n",
      "去掉邻近POI类型分布(57-107)\n",
      "集成学习模型\n",
      "0.8274111675126904\n",
      "[[ 44   5   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  2   7   2   0   0]\n",
      " [ 10   1   2   6   0]\n",
      " [  2   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79        49\n",
      "           1       0.89      0.97      0.92       115\n",
      "           2       0.50      0.18      0.27        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.62      0.47      0.49       197\n",
      "weighted avg       0.82      0.83      0.80       197\n",
      "\n",
      "######################################################\n",
      "去掉停留区面积(108)\n",
      "集成学习模型\n",
      "0.8274111675126904\n",
      "[[ 42   7   0   0   0]\n",
      " [  3 112   0   0   0]\n",
      " [  0   7   3   1   0]\n",
      " [  8   4   1   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        49\n",
      "           1       0.85      0.97      0.91       115\n",
      "           2       0.75      0.27      0.40        11\n",
      "           3       0.86      0.32      0.46        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.65      0.48      0.52       197\n",
      "weighted avg       0.81      0.83      0.80       197\n",
      "\n",
      "######################################################\n",
      "去掉最后三列(109-111)\n",
      "集成学习模型\n",
      "0.8071065989847716\n",
      "[[ 40   9   0   0   0]\n",
      " [  5 110   0   0   0]\n",
      " [  0   8   3   0   0]\n",
      " [  4   7   2   6   0]\n",
      " [  1   2   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        49\n",
      "           1       0.81      0.96      0.88       115\n",
      "           2       0.60      0.27      0.37        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81       197\n",
      "   macro avg       0.64      0.47      0.51       197\n",
      "weighted avg       0.80      0.81      0.78       197\n",
      "\n",
      "######################################################\n",
      "去掉该区域临近道路类型(56->改为one-hot编码)\n",
      "集成学习模型\n",
      "0.8223350253807107\n",
      "[[ 42   7   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  1   4   3   3   0]\n",
      " [  7   4   2   6   0]\n",
      " [  2   0   0   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        49\n",
      "           1       0.88      0.97      0.92       115\n",
      "           2       0.60      0.27      0.37        11\n",
      "           3       0.60      0.32      0.41        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.82       197\n",
      "   macro avg       0.57      0.48      0.50       197\n",
      "weighted avg       0.79      0.82      0.80       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去掉停留时长分布\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "del_first = [1, 18, 42, 54, 57, 108 , 109]\n",
    "del_end = [17, 41, 53, 55, 107, 108, 111]\n",
    "state = ['去掉停留时长分布(1-17){左右端点均包括}','去掉停留时段分布(18-41)','去掉不同时段的停留频次分布(42-53)',\\\n",
    "         '去掉停留点业务类型分布(54-55)','去掉邻近POI类型分布(57-107)',\\\n",
    "         '去掉停留区面积(108)','去掉最后三列(109-111)']\n",
    "state_num = 0\n",
    "for first, end in zip(del_first, del_end):\n",
    "    data_1 = data.drop(labels=[str(i) for i in range(first,end+1)], axis=1)\n",
    "    X = data_1.drop(['112'], axis = 1)\n",
    "    X = data_1.drop(['0'], axis = 1)\n",
    "    y = data_1['112']\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "    print(state[state_num])\n",
    "    state_num += 1\n",
    "    print(\"集成学习模型\")\n",
    "    model = EC(svm_num=2, rf_num=1)\n",
    "    mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "    model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "    model.second_fit(X_train, y_train)\n",
    "    pred0=model.model_test(X_test)\n",
    "    model.pred(y_test, pred0)\n",
    "    print(\"######################################################\")\n",
    "    \n",
    "data_1 = data.drop(labels=['motorway','primary','residential','secondary','service','tertiary','trunk','unclassified'], axis=1)\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print('去掉该区域临近道路类型(56->改为one-hot编码)')\n",
    "print(\"集成学习模型\")\n",
    "model = EC(svm_num=2, rf_num=1)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred0=model.model_test(X_test)\n",
    "model.pred(y_test, pred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a82ee394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉停留时长分布(1-17){左右端点均包括}\n",
      "集成学习模型\n",
      "0.8477157360406091\n",
      "[[ 42   7   0   0   0]\n",
      " [  5 109   1   0   0]\n",
      " [  1   3   7   0   0]\n",
      " [  3   5   2   9   0]\n",
      " [  1   0   2   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        49\n",
      "           1       0.88      0.95      0.91       115\n",
      "           2       0.58      0.64      0.61        11\n",
      "           3       1.00      0.47      0.64        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.65      0.58      0.60       197\n",
      "weighted avg       0.84      0.85      0.84       197\n",
      "\n",
      "######################################################\n",
      "去掉停留时段分布(18-41)\n",
      "集成学习模型\n",
      "0.883248730964467\n",
      "[[ 44   5   0   0   0]\n",
      " [  4 109   2   0   0]\n",
      " [  0   2   9   0   0]\n",
      " [  2   3   1  11   2]\n",
      " [  0   0   1   1   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        49\n",
      "           1       0.92      0.95      0.93       115\n",
      "           2       0.69      0.82      0.75        11\n",
      "           3       0.92      0.58      0.71        19\n",
      "           4       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.88       197\n",
      "   macro avg       0.75      0.72      0.72       197\n",
      "weighted avg       0.89      0.88      0.88       197\n",
      "\n",
      "######################################################\n",
      "去掉不同时段的停留频次分布(42-53)\n",
      "集成学习模型\n",
      "0.868020304568528\n",
      "[[ 45   3   1   0   0]\n",
      " [  4 110   0   1   0]\n",
      " [  0   3   8   0   0]\n",
      " [  5   4   3   7   0]\n",
      " [  1   0   1   0   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        49\n",
      "           1       0.92      0.96      0.94       115\n",
      "           2       0.62      0.73      0.67        11\n",
      "           3       0.88      0.37      0.52        19\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.87       197\n",
      "   macro avg       0.85      0.66      0.70       197\n",
      "weighted avg       0.87      0.87      0.86       197\n",
      "\n",
      "######################################################\n",
      "去掉停留点业务类型分布(54-55)\n",
      "集成学习模型\n",
      "0.8629441624365483\n",
      "[[ 45   4   0   0   0]\n",
      " [  3 111   1   0   0]\n",
      " [  0   4   7   0   0]\n",
      " [  6   4   2   7   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        49\n",
      "           1       0.90      0.97      0.93       115\n",
      "           2       0.64      0.64      0.64        11\n",
      "           3       1.00      0.37      0.54        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.86       197\n",
      "   macro avg       0.67      0.58      0.59       197\n",
      "weighted avg       0.86      0.86      0.84       197\n",
      "\n",
      "######################################################\n",
      "去掉邻近POI类型分布(57-107)\n",
      "集成学习模型\n",
      "0.8426395939086294\n",
      "[[ 45   4   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  2   5   4   0   0]\n",
      " [ 10   0   3   6   0]\n",
      " [  2   0   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        49\n",
      "           1       0.93      0.97      0.94       115\n",
      "           2       0.50      0.36      0.42        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.63      0.51      0.53       197\n",
      "weighted avg       0.84      0.84      0.82       197\n",
      "\n",
      "######################################################\n",
      "去掉停留区面积(108)\n",
      "集成学习模型\n",
      "0.8527918781725888\n",
      "[[ 44   5   0   0   0]\n",
      " [  3 111   1   0   0]\n",
      " [  0   4   7   0   0]\n",
      " [  6   4   3   6   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        49\n",
      "           1       0.89      0.97      0.92       115\n",
      "           2       0.58      0.64      0.61        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.66      0.56      0.57       197\n",
      "weighted avg       0.85      0.85      0.83       197\n",
      "\n",
      "######################################################\n",
      "去掉最后三列(109-111)\n",
      "集成学习模型\n",
      "0.8274111675126904\n",
      "[[ 40   9   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  0   5   6   0   0]\n",
      " [  4   6   3   6   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       0.60      0.55      0.57        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.65      0.53      0.55       197\n",
      "weighted avg       0.82      0.83      0.81       197\n",
      "\n",
      "######################################################\n",
      "去掉该区域临近道路类型(56->改为one-hot编码)\n",
      "集成学习模型\n",
      "0.8477157360406091\n",
      "[[ 43   6   0   0   0]\n",
      " [  5 109   1   0   0]\n",
      " [  0   3   8   0   0]\n",
      " [  5   5   2   7   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83        49\n",
      "           1       0.88      0.95      0.91       115\n",
      "           2       0.67      0.73      0.70        11\n",
      "           3       1.00      0.37      0.54        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.67      0.58      0.60       197\n",
      "weighted avg       0.84      0.85      0.83       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去掉停留时长分布\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "del_first = [1, 18, 42, 54, 57, 108 , 109]\n",
    "del_end = [17, 41, 53, 55, 107, 108, 111]\n",
    "state = ['去掉停留时长分布(1-17){左右端点均包括}','去掉停留时段分布(18-41)','去掉不同时段的停留频次分布(42-53)',\\\n",
    "         '去掉停留点业务类型分布(54-55)','去掉邻近POI类型分布(57-107)',\\\n",
    "         '去掉停留区面积(108)','去掉最后三列(109-111)']\n",
    "state_num = 0\n",
    "for first, end in zip(del_first, del_end):\n",
    "    data_1 = data.drop(labels=[str(i) for i in range(first,end+1)], axis=1)\n",
    "    X = data_1.drop(['112'], axis = 1)\n",
    "    X = data_1.drop(['0'], axis = 1)\n",
    "    y = data_1['112']\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "    print(state[state_num])\n",
    "    state_num += 1\n",
    "    print(\"集成学习模型\")\n",
    "    model = EC(svm_num=60, rf_num=10)\n",
    "    mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "    model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "    model.second_fit(X_train, y_train)\n",
    "    pred0=model.model_test(X_test)\n",
    "    model.pred(y_test, pred0)\n",
    "    print(\"######################################################\")\n",
    "    \n",
    "data_1 = data.drop(labels=['motorway','primary','residential','secondary','service','tertiary','trunk','unclassified'], axis=1)\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print('去掉该区域临近道路类型(56->改为one-hot编码)')\n",
    "print(\"集成学习模型\")\n",
    "model = EC(svm_num=60, rf_num=10)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred0=model.model_test(X_test)\n",
    "model.pred(y_test, pred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f001b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉停留时长分布(1-17){左右端点均包括}\n",
      "集成学习模型\n",
      "0.8527918781725888\n",
      "[[ 42   7   0   0   0]\n",
      " [  5 110   0   0   0]\n",
      " [  1   3   7   0   0]\n",
      " [  2   6   2   9   0]\n",
      " [  0   1   1   1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85        49\n",
      "           1       0.87      0.96      0.91       115\n",
      "           2       0.70      0.64      0.67        11\n",
      "           3       0.90      0.47      0.62        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.66      0.58      0.61       197\n",
      "weighted avg       0.84      0.85      0.84       197\n",
      "\n",
      "######################################################\n",
      "去掉停留时段分布(18-41)\n",
      "集成学习模型\n",
      "0.8781725888324873\n",
      "[[ 45   4   0   0   0]\n",
      " [  4 109   2   0   0]\n",
      " [  0   2   9   0   0]\n",
      " [  3   3   2   9   2]\n",
      " [  0   0   1   1   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        49\n",
      "           1       0.92      0.95      0.94       115\n",
      "           2       0.64      0.82      0.72        11\n",
      "           3       0.90      0.47      0.62        19\n",
      "           4       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.88       197\n",
      "   macro avg       0.73      0.70      0.70       197\n",
      "weighted avg       0.88      0.88      0.87       197\n",
      "\n",
      "######################################################\n",
      "去掉不同时段的停留频次分布(42-53)\n",
      "集成学习模型\n",
      "0.868020304568528\n",
      "[[ 45   3   1   0   0]\n",
      " [  4 110   1   0   0]\n",
      " [  0   3   8   0   0]\n",
      " [  4   6   2   7   0]\n",
      " [  1   0   1   0   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87        49\n",
      "           1       0.90      0.96      0.93       115\n",
      "           2       0.62      0.73      0.67        11\n",
      "           3       1.00      0.37      0.54        19\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.87       197\n",
      "   macro avg       0.87      0.66      0.70       197\n",
      "weighted avg       0.88      0.87      0.86       197\n",
      "\n",
      "######################################################\n",
      "去掉停留点业务类型分布(54-55)\n",
      "集成学习模型\n",
      "0.8629441624365483\n",
      "[[ 45   4   0   0   0]\n",
      " [  3 111   1   0   0]\n",
      " [  0   4   7   0   0]\n",
      " [  5   5   2   7   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87        49\n",
      "           1       0.89      0.97      0.92       115\n",
      "           2       0.64      0.64      0.64        11\n",
      "           3       1.00      0.37      0.54        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.86       197\n",
      "   macro avg       0.67      0.58      0.59       197\n",
      "weighted avg       0.86      0.86      0.84       197\n",
      "\n",
      "######################################################\n",
      "去掉邻近POI类型分布(57-107)\n",
      "集成学习模型\n",
      "0.8426395939086294\n",
      "[[ 45   4   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  2   5   4   0   0]\n",
      " [ 10   0   3   6   0]\n",
      " [  2   0   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        49\n",
      "           1       0.93      0.97      0.94       115\n",
      "           2       0.50      0.36      0.42        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84       197\n",
      "   macro avg       0.63      0.51      0.53       197\n",
      "weighted avg       0.84      0.84      0.82       197\n",
      "\n",
      "######################################################\n",
      "去掉停留区面积(108)\n",
      "集成学习模型\n",
      "0.8527918781725888\n",
      "[[ 44   5   0   0   0]\n",
      " [  3 111   1   0   0]\n",
      " [  0   4   7   0   0]\n",
      " [  4   6   3   6   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87        49\n",
      "           1       0.87      0.97      0.92       115\n",
      "           2       0.58      0.64      0.61        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.66      0.56      0.58       197\n",
      "weighted avg       0.85      0.85      0.83       197\n",
      "\n",
      "######################################################\n",
      "去掉最后三列(109-111)\n",
      "集成学习模型\n",
      "0.8274111675126904\n",
      "[[ 40   9   0   0   0]\n",
      " [  4 111   0   0   0]\n",
      " [  0   5   6   0   0]\n",
      " [  4   6   3   6   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        49\n",
      "           1       0.84      0.97      0.90       115\n",
      "           2       0.60      0.55      0.57        11\n",
      "           3       1.00      0.32      0.48        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.83       197\n",
      "   macro avg       0.65      0.53      0.55       197\n",
      "weighted avg       0.82      0.83      0.81       197\n",
      "\n",
      "######################################################\n",
      "去掉该区域临近道路类型(56->改为one-hot编码)\n",
      "集成学习模型\n",
      "0.8477157360406091\n",
      "[[ 43   6   0   0   0]\n",
      " [  5 109   1   0   0]\n",
      " [  0   3   8   0   0]\n",
      " [  5   5   2   7   0]\n",
      " [  1   1   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83        49\n",
      "           1       0.88      0.95      0.91       115\n",
      "           2       0.67      0.73      0.70        11\n",
      "           3       1.00      0.37      0.54        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85       197\n",
      "   macro avg       0.67      0.58      0.60       197\n",
      "weighted avg       0.84      0.85      0.83       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去掉停留时长分布\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "del_first = [1, 18, 42, 54, 57, 108 , 109]\n",
    "del_end = [17, 41, 53, 55, 107, 108, 111]\n",
    "state = ['去掉停留时长分布(1-17){左右端点均包括}','去掉停留时段分布(18-41)','去掉不同时段的停留频次分布(42-53)',\\\n",
    "         '去掉停留点业务类型分布(54-55)','去掉邻近POI类型分布(57-107)',\\\n",
    "         '去掉停留区面积(108)','去掉最后三列(109-111)']\n",
    "state_num = 0\n",
    "for first, end in zip(del_first, del_end):\n",
    "    data_1 = data.drop(labels=[str(i) for i in range(first,end+1)], axis=1)\n",
    "    X = data_1.drop(['112'], axis = 1)\n",
    "    X = data_1.drop(['0'], axis = 1)\n",
    "    y = data_1['112']\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "    print(state[state_num])\n",
    "    state_num += 1\n",
    "    print(\"集成学习模型\")\n",
    "    model = EC(svm_num=60, rf_num=30)\n",
    "    mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "    model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "    model.second_fit(X_train, y_train)\n",
    "    pred0=model.model_test(X_test)\n",
    "    model.pred(y_test, pred0)\n",
    "    print(\"######################################################\")\n",
    "    \n",
    "data_1 = data.drop(labels=['motorway','primary','residential','secondary','service','tertiary','trunk','unclassified'], axis=1)\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print('去掉该区域临近道路类型(56->改为one-hot编码)')\n",
    "print(\"集成学习模型\")\n",
    "model = EC(svm_num=60, rf_num=30)\n",
    "mistake_X_all, mistake_y_all = model.svm_fit(X_train, y_train)\n",
    "model.rf_fit(mistake_X_all, mistake_y_all)\n",
    "model.second_fit(X_train, y_train)\n",
    "pred0=model.model_test(X_test)\n",
    "model.pred(y_test, pred0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a38758",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfc8dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉停留时长分布(1-17){左右端点均包括}\n",
      "xgboost模型\n",
      "[09:32:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59659\teval-mlogloss:1.59683\n",
      "[2000]\ttrain-mlogloss:0.27787\teval-mlogloss:0.28416\n",
      "[2944]\ttrain-mlogloss:0.27546\teval-mlogloss:0.28157\n",
      "0.9543147208121827\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   0   0  19   0]\n",
      " [  0   0   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.95      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.86      1.00      0.93        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.76      0.69      0.71       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉停留时段分布(18-41)\n",
      "xgboost模型\n",
      "[09:32:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59598\teval-mlogloss:1.59624\n",
      "[2000]\ttrain-mlogloss:0.27732\teval-mlogloss:0.28276\n",
      "[3137]\ttrain-mlogloss:0.27492\teval-mlogloss:0.28013\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   0   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.94      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.86      0.95      0.90        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.76      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉不同时段的停留频次分布(42-53)\n",
      "xgboost模型\n",
      "[09:33:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59703\teval-mlogloss:1.59781\n",
      "[2000]\ttrain-mlogloss:0.27775\teval-mlogloss:0.28526\n",
      "[3113]\ttrain-mlogloss:0.27503\teval-mlogloss:0.28231\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.93      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.90      0.95      0.92        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.77      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉停留点业务类型分布(54-55)\n",
      "xgboost模型\n",
      "[09:33:18] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59796\teval-mlogloss:1.59821\n",
      "[2000]\ttrain-mlogloss:0.27873\teval-mlogloss:0.28714\n",
      "[3506]\ttrain-mlogloss:0.27435\teval-mlogloss:0.28242\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.93      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.90      0.95      0.92        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.77      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉邻近POI类型分布(57-107)\n",
      "xgboost模型\n",
      "[09:33:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59566\teval-mlogloss:1.59584\n",
      "[2000]\ttrain-mlogloss:0.27781\teval-mlogloss:0.28413\n",
      "[3137]\ttrain-mlogloss:0.27496\teval-mlogloss:0.28104\n",
      "0.9543147208121827\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   0   0  19   0]\n",
      " [  0   0   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.95      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.86      1.00      0.93        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.76      0.69      0.71       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉停留区面积(108)\n",
      "xgboost模型\n",
      "[09:33:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59388\teval-mlogloss:1.59378\n",
      "[2000]\ttrain-mlogloss:0.28069\teval-mlogloss:0.28521\n",
      "[2945]\ttrain-mlogloss:0.27768\teval-mlogloss:0.28199\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.93      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.90      0.95      0.92        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.77      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n",
      "######################################################\n",
      "去掉最后三列(109-111)\n",
      "xgboost模型\n",
      "[09:33:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59581\teval-mlogloss:1.59590\n",
      "[2000]\ttrain-mlogloss:0.27727\teval-mlogloss:0.28049\n",
      "[2891]\ttrain-mlogloss:0.27511\teval-mlogloss:0.27811\n",
      "0.934010152284264\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0  10   1   0   0]\n",
      " [  0   0   0  19   0]\n",
      " [  0   0   0   3   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.92      1.00      0.96       115\n",
      "           2       1.00      0.09      0.17        11\n",
      "           3       0.86      1.00      0.93        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.76      0.62      0.61       197\n",
      "weighted avg       0.92      0.93      0.91       197\n",
      "\n",
      "######################################################\n",
      "去掉该区域临近道路类型(56->改为one-hot编码)\n",
      "xgboost模型\n",
      "[09:34:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59465\teval-mlogloss:1.59476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain-mlogloss:0.27763\teval-mlogloss:0.28445\n",
      "[3835]\ttrain-mlogloss:0.27399\teval-mlogloss:0.28050\n",
      "0.949238578680203\n",
      "[[ 49   0   0   0   0]\n",
      " [  0 115   0   0   0]\n",
      " [  0   6   5   0   0]\n",
      " [  0   1   0  18   0]\n",
      " [  0   1   0   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       0.93      1.00      0.97       115\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.90      0.95      0.92        19\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.77      0.68      0.70       197\n",
      "weighted avg       0.94      0.95      0.94       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去掉停留时长分布\n",
    "data = pd.read_csv('D:\\\\data\\\\挖掘运输热点数据\\\\6.29新的分类数据\\\\train_and_all处理后的训练数据.csv')\n",
    "del_first = [1, 18, 42, 54, 57, 108 , 109]\n",
    "del_end = [17, 41, 53, 55, 107, 108, 111]\n",
    "state = ['去掉停留时长分布(1-17){左右端点均包括}','去掉停留时段分布(18-41)','去掉不同时段的停留频次分布(42-53)',\\\n",
    "         '去掉停留点业务类型分布(54-55)','去掉邻近POI类型分布(57-107)',\\\n",
    "         '去掉停留区面积(108)','去掉最后三列(109-111)']\n",
    "state_num = 0\n",
    "for first, end in zip(del_first, del_end):\n",
    "    data_1 = data.drop(labels=[str(i) for i in range(first,end+1)], axis=1)\n",
    "    X = data_1.drop(['112'], axis = 1)\n",
    "    X = data_1.drop(['0'], axis = 1)\n",
    "    y = data_1['112']\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "    print(state[state_num])\n",
    "    state_num += 1\n",
    "    print(\"xgboost模型\")\n",
    "    model = EC()\n",
    "    pred = model.model_xgboost(X_train,  y_train, X_test, y_test)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    model.pred(y_test, pred)\n",
    "    print(\"######################################################\")\n",
    "    \n",
    "data_1 = data.drop(labels=['motorway','primary','residential','secondary','service','tertiary','trunk','unclassified'], axis=1)\n",
    "X = data_1.drop(['112'], axis = 1)\n",
    "X = data_1.drop(['0'], axis = 1)\n",
    "y = data['112']\n",
    "X = X.values\n",
    "y = y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify= y)\n",
    "print('去掉该区域临近道路类型(56->改为one-hot编码)')\n",
    "print(\"xgboost模型\")\n",
    "model = EC()\n",
    "pred = model.model_xgboost(X_train,  y_train, X_test, y_test)\n",
    "pred = np.argmax(pred, axis = 1)\n",
    "model.pred(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
